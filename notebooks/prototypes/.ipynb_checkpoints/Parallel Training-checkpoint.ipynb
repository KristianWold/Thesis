{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from data_encoders import *\n",
    "from parametrizations import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000 0.000 0.000]\n",
      " [1.047 0.349 0.116]\n",
      " [2.094 1.396 0.931]\n",
      " [3.142 3.142 3.142]]\n",
      "[[0.500]\n",
      " [0.675]\n",
      " [1.198]\n",
      " [2.071]]\n"
     ]
    }
   ],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "n_samples = 4\n",
    "n_features = 3\n",
    "n_targets = 1\n",
    "\n",
    "x = np.linspace(0, 2, n_samples)\n",
    "y = x**2\n",
    "y = y - np.min(y)\n",
    "y = y/np.max(y)\n",
    "y = np.pi/2 *y\n",
    "y = y.reshape(-1,1) + 0.5\n",
    "\n",
    "X = np.zeros((n_samples, n_features))\n",
    "X[:,0] = x\n",
    "X[:,1] = x**2\n",
    "X[:,2] = x**3\n",
    "#X[:,3] = x**4\n",
    "\n",
    "\n",
    "\n",
    "X = X - np.min(X, axis=0).reshape(1,-1)\n",
    "X = X/np.max(X, axis=0).reshape(1,-1)\n",
    "X = np.pi * X\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "np.random.seed(42)\n",
    "model = ParallelModel(n_features=n_features,\n",
    "                      n_targets=n_targets,\n",
    "                      reps=reps,\n",
    "                      backend=backend, \n",
    "                      shots=100000)\n",
    "\n",
    "optimizer = Adam()\n",
    "optimizer.initialize(model.theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502760a81e5f473d955cc48a1ff28d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.357, mse=0.294, y_pred.flatten()=array([0.917, 0.783, 1.498, 1.122])\n",
      "loss=0.373, mse=0.295, y_pred.flatten()=array([0.727, 0.682, 1.496, 1.052])\n",
      "loss=0.378, mse=0.268, y_pred.flatten()=array([0.572, 0.584, 1.468, 1.077])\n",
      "loss=0.382, mse=0.224, y_pred.flatten()=array([0.455, 0.477, 1.384, 1.164])\n",
      "loss=0.396, mse=0.170, y_pred.flatten()=array([0.392, 0.400, 1.276, 1.305])\n",
      "loss=0.402, mse=0.123, y_pred.flatten()=array([0.388, 0.347, 1.130, 1.464])\n",
      "loss=0.410, mse=0.088, y_pred.flatten()=array([0.447, 0.353, 0.983, 1.626])\n",
      "loss=0.411, mse=0.069, y_pred.flatten()=array([0.517, 0.406, 0.861, 1.773])\n",
      "loss=0.411, mse=0.063, y_pred.flatten()=array([0.589, 0.472, 0.798, 1.866])\n",
      "loss=0.409, mse=0.060, y_pred.flatten()=array([0.639, 0.504, 0.781, 1.937])\n",
      "loss=0.411, mse=0.058, y_pred.flatten()=array([0.683, 0.528, 0.787, 1.996])\n",
      "loss=0.409, mse=0.056, y_pred.flatten()=array([0.708, 0.534, 0.797, 2.048])\n",
      "loss=0.414, mse=0.056, y_pred.flatten()=array([0.720, 0.529, 0.806, 2.105])\n",
      "loss=0.417, mse=0.056, y_pred.flatten()=array([0.713, 0.518, 0.816, 2.163])\n",
      "loss=0.414, mse=0.062, y_pred.flatten()=array([0.699, 0.487, 0.806, 2.212])\n",
      "loss=0.416, mse=0.072, y_pred.flatten()=array([0.674, 0.446, 0.798, 2.285])\n",
      "loss=0.416, mse=0.086, y_pred.flatten()=array([0.627, 0.398, 0.780, 2.349])\n",
      "loss=0.417, mse=0.098, y_pred.flatten()=array([0.570, 0.364, 0.784, 2.418])\n",
      "loss=0.421, mse=0.113, y_pred.flatten()=array([0.530, 0.332, 0.787, 2.474])\n",
      "loss=0.428, mse=0.121, y_pred.flatten()=array([0.488, 0.321, 0.808, 2.527])\n",
      "loss=0.422, mse=0.133, y_pred.flatten()=array([0.463, 0.308, 0.819, 2.573])\n",
      "loss=0.424, mse=0.144, y_pred.flatten()=array([0.456, 0.305, 0.826, 2.616])\n",
      "loss=0.414, mse=0.152, y_pred.flatten()=array([0.441, 0.299, 0.833, 2.647])\n",
      "loss=0.419, mse=0.161, y_pred.flatten()=array([0.438, 0.292, 0.841, 2.677])\n",
      "loss=0.422, mse=0.170, y_pred.flatten()=array([0.441, 0.299, 0.835, 2.706])\n",
      "loss=0.421, mse=0.181, y_pred.flatten()=array([0.448, 0.295, 0.821, 2.730])\n",
      "loss=0.421, mse=0.190, y_pred.flatten()=array([0.453, 0.295, 0.809, 2.752])\n",
      "loss=0.423, mse=0.195, y_pred.flatten()=array([0.448, 0.300, 0.794, 2.760])\n",
      "loss=0.418, mse=0.206, y_pred.flatten()=array([0.441, 0.293, 0.780, 2.779])\n",
      "loss=0.424, mse=0.212, y_pred.flatten()=array([0.435, 0.284, 0.760, 2.776])\n",
      "loss=0.424, mse=0.214, y_pred.flatten()=array([0.424, 0.285, 0.742, 2.771])\n",
      "loss=0.424, mse=0.208, y_pred.flatten()=array([0.423, 0.308, 0.724, 2.755])\n",
      "loss=0.422, mse=0.202, y_pred.flatten()=array([0.431, 0.330, 0.706, 2.735])\n",
      "loss=0.427, mse=0.198, y_pred.flatten()=array([0.433, 0.345, 0.697, 2.724])\n",
      "loss=0.426, mse=0.194, y_pred.flatten()=array([0.440, 0.366, 0.678, 2.710])\n",
      "loss=0.425, mse=0.193, y_pred.flatten()=array([0.440, 0.391, 0.668, 2.709])\n",
      "loss=0.421, mse=0.198, y_pred.flatten()=array([0.443, 0.391, 0.654, 2.712])\n",
      "loss=0.424, mse=0.198, y_pred.flatten()=array([0.431, 0.389, 0.652, 2.710])\n",
      "loss=0.425, mse=0.206, y_pred.flatten()=array([0.425, 0.381, 0.652, 2.729])\n",
      "loss=0.424, mse=0.207, y_pred.flatten()=array([0.409, 0.365, 0.666, 2.734])\n",
      "loss=0.422, mse=0.214, y_pred.flatten()=array([0.387, 0.351, 0.672, 2.752])\n",
      "loss=0.418, mse=0.216, y_pred.flatten()=array([0.376, 0.346, 0.678, 2.758])\n",
      "loss=0.425, mse=0.216, y_pred.flatten()=array([0.367, 0.344, 0.689, 2.762])\n",
      "loss=0.422, mse=0.218, y_pred.flatten()=array([0.362, 0.329, 0.693, 2.762])\n",
      "loss=0.422, mse=0.217, y_pred.flatten()=array([0.357, 0.333, 0.703, 2.767])\n",
      "loss=0.425, mse=0.216, y_pred.flatten()=array([0.356, 0.334, 0.703, 2.765])\n",
      "loss=0.427, mse=0.209, y_pred.flatten()=array([0.364, 0.342, 0.702, 2.748])\n",
      "loss=0.427, mse=0.204, y_pred.flatten()=array([0.378, 0.352, 0.690, 2.735])\n",
      "loss=0.420, mse=0.201, y_pred.flatten()=array([0.391, 0.369, 0.672, 2.720])\n",
      "loss=0.424, mse=0.196, y_pred.flatten()=array([0.409, 0.378, 0.667, 2.707])\n",
      "loss=0.422, mse=0.190, y_pred.flatten()=array([0.417, 0.387, 0.661, 2.688])\n",
      "loss=0.422, mse=0.188, y_pred.flatten()=array([0.421, 0.388, 0.664, 2.686])\n",
      "loss=0.422, mse=0.188, y_pred.flatten()=array([0.427, 0.381, 0.667, 2.687])\n",
      "loss=0.420, mse=0.189, y_pred.flatten()=array([0.420, 0.369, 0.681, 2.693])\n",
      "loss=0.426, mse=0.192, y_pred.flatten()=array([0.410, 0.356, 0.689, 2.704])\n",
      "loss=0.428, mse=0.193, y_pred.flatten()=array([0.414, 0.345, 0.699, 2.710])\n",
      "loss=0.422, mse=0.191, y_pred.flatten()=array([0.403, 0.342, 0.718, 2.713])\n",
      "loss=0.423, mse=0.191, y_pred.flatten()=array([0.404, 0.331, 0.726, 2.715])\n",
      "loss=0.420, mse=0.192, y_pred.flatten()=array([0.402, 0.326, 0.726, 2.715])\n",
      "loss=0.423, mse=0.193, y_pred.flatten()=array([0.392, 0.317, 0.738, 2.720])\n",
      "loss=0.426, mse=0.191, y_pred.flatten()=array([0.394, 0.322, 0.734, 2.714])\n",
      "loss=0.425, mse=0.189, y_pred.flatten()=array([0.397, 0.319, 0.734, 2.707])\n",
      "loss=0.426, mse=0.180, y_pred.flatten()=array([0.403, 0.329, 0.740, 2.689])\n",
      "loss=0.426, mse=0.179, y_pred.flatten()=array([0.416, 0.333, 0.731, 2.681])\n",
      "loss=0.426, mse=0.177, y_pred.flatten()=array([0.418, 0.337, 0.732, 2.678])\n",
      "loss=0.426, mse=0.171, y_pred.flatten()=array([0.430, 0.344, 0.734, 2.664])\n",
      "loss=0.422, mse=0.168, y_pred.flatten()=array([0.437, 0.347, 0.732, 2.657])\n",
      "loss=0.425, mse=0.166, y_pred.flatten()=array([0.446, 0.353, 0.731, 2.655])\n",
      "loss=0.424, mse=0.166, y_pred.flatten()=array([0.434, 0.345, 0.735, 2.651])\n",
      "loss=0.425, mse=0.168, y_pred.flatten()=array([0.427, 0.341, 0.735, 2.654])\n",
      "loss=0.421, mse=0.171, y_pred.flatten()=array([0.420, 0.337, 0.732, 2.658])\n",
      "loss=0.426, mse=0.173, y_pred.flatten()=array([0.416, 0.328, 0.742, 2.668])\n",
      "loss=0.423, mse=0.174, y_pred.flatten()=array([0.406, 0.323, 0.749, 2.673])\n",
      "loss=0.425, mse=0.181, y_pred.flatten()=array([0.396, 0.310, 0.753, 2.689])\n",
      "loss=0.427, mse=0.184, y_pred.flatten()=array([0.388, 0.302, 0.757, 2.695])\n",
      "loss=0.417, mse=0.185, y_pred.flatten()=array([0.388, 0.307, 0.756, 2.701])\n",
      "loss=0.424, mse=0.182, y_pred.flatten()=array([0.397, 0.307, 0.757, 2.693])\n",
      "loss=0.428, mse=0.182, y_pred.flatten()=array([0.395, 0.307, 0.746, 2.684])\n",
      "loss=0.424, mse=0.178, y_pred.flatten()=array([0.411, 0.318, 0.744, 2.678])\n",
      "loss=0.421, mse=0.172, y_pred.flatten()=array([0.410, 0.338, 0.735, 2.662])\n",
      "loss=0.422, mse=0.165, y_pred.flatten()=array([0.425, 0.344, 0.738, 2.647])\n",
      "loss=0.420, mse=0.164, y_pred.flatten()=array([0.433, 0.353, 0.728, 2.641])\n",
      "loss=0.424, mse=0.162, y_pred.flatten()=array([0.432, 0.364, 0.720, 2.636])\n",
      "loss=0.429, mse=0.162, y_pred.flatten()=array([0.435, 0.362, 0.720, 2.634])\n",
      "loss=0.424, mse=0.162, y_pred.flatten()=array([0.431, 0.359, 0.724, 2.636])\n",
      "loss=0.429, mse=0.166, y_pred.flatten()=array([0.424, 0.355, 0.722, 2.645])\n",
      "loss=0.421, mse=0.170, y_pred.flatten()=array([0.412, 0.355, 0.723, 2.656])\n",
      "loss=0.428, mse=0.175, y_pred.flatten()=array([0.406, 0.340, 0.725, 2.666])\n",
      "loss=0.421, mse=0.177, y_pred.flatten()=array([0.403, 0.337, 0.731, 2.677])\n",
      "loss=0.424, mse=0.178, y_pred.flatten()=array([0.413, 0.338, 0.732, 2.683])\n",
      "loss=0.426, mse=0.178, y_pred.flatten()=array([0.406, 0.337, 0.733, 2.682])\n",
      "loss=0.425, mse=0.180, y_pred.flatten()=array([0.406, 0.346, 0.722, 2.686])\n",
      "loss=0.421, mse=0.183, y_pred.flatten()=array([0.406, 0.346, 0.718, 2.691])\n",
      "loss=0.421, mse=0.189, y_pred.flatten()=array([0.412, 0.343, 0.709, 2.702])\n",
      "loss=0.424, mse=0.188, y_pred.flatten()=array([0.406, 0.345, 0.711, 2.700])\n",
      "loss=0.424, mse=0.186, y_pred.flatten()=array([0.415, 0.344, 0.710, 2.696])\n",
      "loss=0.423, mse=0.188, y_pred.flatten()=array([0.411, 0.349, 0.703, 2.696])\n",
      "loss=0.422, mse=0.189, y_pred.flatten()=array([0.421, 0.349, 0.699, 2.698])\n",
      "loss=0.426, mse=0.192, y_pred.flatten()=array([0.426, 0.343, 0.701, 2.707])\n",
      "loss=0.425, mse=0.192, y_pred.flatten()=array([0.422, 0.344, 0.703, 2.710])\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    grad = [model.gradient(X, y)]\n",
    "    grad = optimizer(grad)\n",
    "    model.theta += 0.1*grad[0]\n",
    "    y_pred = model.predict(X)\n",
    "    mse = np.mean((y_pred - y)**2)\n",
    "    loss = model.loss(X,y)\n",
    "    #print(loss, model.theta, y_pred.flatten())\n",
    "    print(f\"{loss=:.3f}, {mse=:.3f}, {y_pred.flatten()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 2\n",
    "np.random.seed(42)\n",
    "model = ParallelModel(n_features=n_features,\n",
    "                      n_targets=n_targets,\n",
    "                      reps=reps,\n",
    "                      backend=backend, \n",
    "                      shots=100000)\n",
    "\n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "n_samples = 2\n",
    "n_features = 2\n",
    "n_targets = 1\n",
    "\n",
    "x = np.linspace(0, 2, n_samples)\n",
    "\n",
    "X = np.zeros((n_samples, n_features))\n",
    "X[:,0] = x\n",
    "X[:,1] = x**2\n",
    "\n",
    "\n",
    "\n",
    "X = X - np.min(X, axis=0).reshape(1,-1)\n",
    "X = X/np.max(X, axis=0).reshape(1,-1)\n",
    "X = np.pi * X\n",
    "\n",
    "y = model.predict(X)\n",
    "print(y)\n",
    "\n",
    "loss = model.loss(X,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[0,0], [1,1], [2,2], [3,3]])\n",
    "encoder = ParallelEncoder()\n",
    "\n",
    "\n",
    "features = qk.QuantumRegister(2, name=\"features\")\n",
    "ancilla = qk.QuantumRegister(2, name=\"ancilla_f\")\n",
    "registers = [features, ancilla]\n",
    "circuit = qk.QuantumCircuit(*registers)\n",
    "\n",
    "circuit = encoder(circuit, features, ancilla, data)\n",
    "\n",
    "circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
