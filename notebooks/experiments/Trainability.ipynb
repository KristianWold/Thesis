{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Constant Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = 0.5*np.ones((n,1))\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a9a9ebf61a45368b9ac4aa1804b8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0178221313\n",
      "epoch: 1, loss: 0.0097063581\n",
      "epoch: 2, loss: 0.0067131029\n",
      "epoch: 3, loss: 0.0078419997\n",
      "epoch: 4, loss: 0.0076362788\n",
      "epoch: 5, loss: 0.005991938599999999\n",
      "epoch: 6, loss: 0.0040055114\n",
      "epoch: 7, loss: 0.0022451054\n",
      "epoch: 8, loss: 0.0012120905\n",
      "epoch: 9, loss: 0.0011720341\n",
      "epoch: 10, loss: 0.0012821748\n",
      "epoch: 11, loss: 0.0010129587\n",
      "epoch: 12, loss: 0.0005786793999999999\n",
      "epoch: 13, loss: 0.0005261932000000002\n",
      "epoch: 14, loss: 0.0007221189999999999\n",
      "epoch: 15, loss: 0.0010464685000000002\n",
      "epoch: 16, loss: 0.0008539471000000001\n",
      "epoch: 17, loss: 0.00048594059999999996\n",
      "epoch: 18, loss: 0.00018171320000000005\n",
      "epoch: 19, loss: 0.0001408177999999999\n",
      "epoch: 20, loss: 0.0002874044\n",
      "epoch: 21, loss: 0.00041206389999999993\n",
      "epoch: 22, loss: 0.00041053840000000003\n",
      "epoch: 23, loss: 0.0002875575999999999\n",
      "epoch: 24, loss: 0.00010620120000000001\n",
      "epoch: 25, loss: 6.0301199999999984e-05\n",
      "epoch: 26, loss: 0.00011942890000000005\n",
      "epoch: 27, loss: 0.0002176227999999999\n",
      "epoch: 28, loss: 0.00024273969999999984\n",
      "epoch: 29, loss: 0.00018848709999999994\n",
      "epoch: 30, loss: 8.778460000000004e-05\n",
      "epoch: 31, loss: 5.227740000000008e-05\n",
      "epoch: 32, loss: 9.319649999999999e-05\n",
      "epoch: 33, loss: 0.00013930360000000003\n",
      "epoch: 34, loss: 0.00017636340000000007\n",
      "epoch: 35, loss: 0.00012885339999999993\n",
      "epoch: 36, loss: 8.880790000000003e-05\n",
      "epoch: 37, loss: 4.2021300000000004e-05\n",
      "epoch: 38, loss: 4.1449900000000004e-05\n",
      "epoch: 39, loss: 5.172479999999999e-05\n",
      "epoch: 40, loss: 7.270189999999993e-05\n",
      "epoch: 41, loss: 7.004799999999999e-05\n",
      "epoch: 42, loss: 6.715789999999992e-05\n",
      "epoch: 43, loss: 4.706240000000003e-05\n",
      "epoch: 44, loss: 2.9437799999999964e-05\n",
      "epoch: 45, loss: 3.671519999999997e-05\n",
      "epoch: 46, loss: 5.891970000000003e-05\n",
      "epoch: 47, loss: 5.3132100000000006e-05\n",
      "epoch: 48, loss: 7.36283e-05\n",
      "epoch: 49, loss: 4.755070000000002e-05\n",
      "epoch: 50, loss: 3.278090000000001e-05\n",
      "epoch: 51, loss: 2.5033499999999983e-05\n",
      "epoch: 52, loss: 3.407769999999999e-05\n",
      "epoch: 53, loss: 2.7431000000000043e-05\n",
      "epoch: 54, loss: 4.800229999999999e-05\n",
      "epoch: 55, loss: 3.9025299999999994e-05\n",
      "epoch: 56, loss: 3.11383e-05\n",
      "epoch: 57, loss: 3.227230000000001e-05\n",
      "epoch: 58, loss: 3.577389999999998e-05\n",
      "epoch: 59, loss: 3.7783699999999975e-05\n",
      "epoch: 60, loss: 3.856689999999997e-05\n",
      "epoch: 61, loss: 3.321589999999996e-05\n",
      "epoch: 62, loss: 2.8621599999999994e-05\n",
      "epoch: 63, loss: 2.5149499999999983e-05\n",
      "epoch: 64, loss: 2.7185600000000054e-05\n",
      "epoch: 65, loss: 3.145650000000001e-05\n",
      "epoch: 66, loss: 4.547499999999999e-05\n",
      "epoch: 67, loss: 3.211310000000006e-05\n",
      "epoch: 68, loss: 2.98524000000001e-05\n",
      "epoch: 69, loss: 2.775230000000001e-05\n",
      "epoch: 70, loss: 3.1490499999999986e-05\n",
      "epoch: 71, loss: 3.055780000000001e-05\n",
      "epoch: 72, loss: 2.044929999999999e-05\n",
      "epoch: 73, loss: 2.7122400000000023e-05\n",
      "epoch: 74, loss: 2.0246999999999977e-05\n",
      "epoch: 75, loss: 2.79588e-05\n",
      "epoch: 76, loss: 2.5026399999999944e-05\n",
      "epoch: 77, loss: 2.6565999999999955e-05\n",
      "epoch: 78, loss: 2.582440000000001e-05\n",
      "epoch: 79, loss: 2.8652599999999984e-05\n",
      "epoch: 80, loss: 2.766689999999997e-05\n",
      "epoch: 81, loss: 2.705389999999998e-05\n",
      "epoch: 82, loss: 3.410580000000001e-05\n",
      "epoch: 83, loss: 2.5479200000000022e-05\n",
      "epoch: 84, loss: 2.090009999999998e-05\n",
      "epoch: 85, loss: 2.4628099999999992e-05\n",
      "epoch: 86, loss: 2.6157299999999998e-05\n",
      "epoch: 87, loss: 2.7794499999999993e-05\n",
      "epoch: 88, loss: 2.174109999999997e-05\n",
      "epoch: 89, loss: 3.207819999999998e-05\n",
      "epoch: 90, loss: 2.317719999999999e-05\n",
      "epoch: 91, loss: 2.4781699999999987e-05\n",
      "epoch: 92, loss: 3.2268899999999965e-05\n",
      "epoch: 93, loss: 2.458989999999994e-05\n",
      "epoch: 94, loss: 3.5471700000000055e-05\n",
      "epoch: 95, loss: 1.7722699999999996e-05\n",
      "epoch: 96, loss: 2.532440000000001e-05\n",
      "epoch: 97, loss: 2.1841600000000028e-05\n",
      "epoch: 98, loss: 3.0006500000000015e-05\n",
      "epoch: 99, loss: 2.1711200000000007e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcf8e677b0a4d908b155a2895df095c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0813334264\n",
      "epoch: 1, loss: 0.0546707414\n",
      "epoch: 2, loss: 0.0312198592\n",
      "epoch: 3, loss: 0.021252478899999996\n",
      "epoch: 4, loss: 0.0171411303\n",
      "epoch: 5, loss: 0.013712524299999999\n",
      "epoch: 6, loss: 0.0127078114\n",
      "epoch: 7, loss: 0.013005496600000001\n",
      "epoch: 8, loss: 0.012627767599999997\n",
      "epoch: 9, loss: 0.011169496499999997\n",
      "epoch: 10, loss: 0.008992088\n",
      "epoch: 11, loss: 0.007351122000000001\n",
      "epoch: 12, loss: 0.005974871399999999\n",
      "epoch: 13, loss: 0.005208370199999999\n",
      "epoch: 14, loss: 0.004743696\n",
      "epoch: 15, loss: 0.0045519971\n",
      "epoch: 16, loss: 0.0042605570999999995\n",
      "epoch: 17, loss: 0.004307673000000001\n",
      "epoch: 18, loss: 0.0039235046000000015\n",
      "epoch: 19, loss: 0.0035863454\n",
      "epoch: 20, loss: 0.0030108192000000006\n",
      "epoch: 21, loss: 0.0024212284000000002\n",
      "epoch: 22, loss: 0.0018308598000000003\n",
      "epoch: 23, loss: 0.0013725313000000003\n",
      "epoch: 24, loss: 0.0009791660000000003\n",
      "epoch: 25, loss: 0.0007654168999999999\n",
      "epoch: 26, loss: 0.0008012596\n",
      "epoch: 27, loss: 0.0009620305000000002\n",
      "epoch: 28, loss: 0.0011191002\n",
      "epoch: 29, loss: 0.0013328378000000004\n",
      "epoch: 30, loss: 0.0013061043999999997\n",
      "epoch: 31, loss: 0.0011540531999999998\n",
      "epoch: 32, loss: 0.0009987242000000002\n",
      "epoch: 33, loss: 0.0008605177999999999\n",
      "epoch: 34, loss: 0.0006582891999999999\n",
      "epoch: 35, loss: 0.0005213969999999999\n",
      "epoch: 36, loss: 0.0004437384000000002\n",
      "epoch: 37, loss: 0.0004003922\n",
      "epoch: 38, loss: 0.0003913854999999998\n",
      "epoch: 39, loss: 0.00037331870000000005\n",
      "epoch: 40, loss: 0.00033092930000000015\n",
      "epoch: 41, loss: 0.00027745110000000004\n",
      "epoch: 42, loss: 0.00021295209999999998\n",
      "epoch: 43, loss: 0.00014342519999999994\n",
      "epoch: 44, loss: 0.00012589470000000006\n",
      "epoch: 45, loss: 9.673939999999998e-05\n",
      "epoch: 46, loss: 9.5874e-05\n",
      "epoch: 47, loss: 9.673670000000005e-05\n",
      "epoch: 48, loss: 0.00011142350000000004\n",
      "epoch: 49, loss: 0.00011944039999999996\n",
      "epoch: 50, loss: 0.00010789489999999991\n",
      "epoch: 51, loss: 0.00011236609999999994\n",
      "epoch: 52, loss: 9.651409999999992e-05\n",
      "epoch: 53, loss: 7.383959999999997e-05\n",
      "epoch: 54, loss: 4.2130799999999986e-05\n",
      "epoch: 55, loss: 3.761369999999995e-05\n",
      "epoch: 56, loss: 3.7027400000000024e-05\n",
      "epoch: 57, loss: 4.032120000000001e-05\n",
      "epoch: 58, loss: 4.5116699999999994e-05\n",
      "epoch: 59, loss: 4.3252200000000006e-05\n",
      "epoch: 60, loss: 3.936470000000005e-05\n",
      "epoch: 61, loss: 4.09735e-05\n",
      "epoch: 62, loss: 3.943290000000005e-05\n",
      "epoch: 63, loss: 4.090550000000001e-05\n",
      "epoch: 64, loss: 3.026329999999999e-05\n",
      "epoch: 65, loss: 2.755700000000001e-05\n",
      "epoch: 66, loss: 2.56347e-05\n",
      "epoch: 67, loss: 3.441100000000001e-05\n",
      "epoch: 68, loss: 3.2028099999999945e-05\n",
      "epoch: 69, loss: 4.0858399999999975e-05\n",
      "epoch: 70, loss: 3.525089999999996e-05\n",
      "epoch: 71, loss: 4.8923200000000027e-05\n",
      "epoch: 72, loss: 4.080270000000003e-05\n",
      "epoch: 73, loss: 3.423230000000001e-05\n",
      "epoch: 74, loss: 3.356320000000001e-05\n",
      "epoch: 75, loss: 2.7207599999999943e-05\n",
      "epoch: 76, loss: 2.5246899999999977e-05\n",
      "epoch: 77, loss: 2.9583599999999986e-05\n",
      "epoch: 78, loss: 3.607880000000002e-05\n",
      "epoch: 79, loss: 3.970269999999997e-05\n",
      "epoch: 80, loss: 3.785960000000003e-05\n",
      "epoch: 81, loss: 3.571369999999997e-05\n",
      "epoch: 82, loss: 2.582490000000001e-05\n",
      "epoch: 83, loss: 3.3408700000000025e-05\n",
      "epoch: 84, loss: 3.281890000000004e-05\n",
      "epoch: 85, loss: 2.123540000000004e-05\n",
      "epoch: 86, loss: 2.629970000000003e-05\n",
      "epoch: 87, loss: 2.1831800000000068e-05\n",
      "epoch: 88, loss: 3.759989999999995e-05\n",
      "epoch: 89, loss: 2.90166e-05\n",
      "epoch: 90, loss: 3.1191400000000014e-05\n",
      "epoch: 91, loss: 2.9157699999999997e-05\n",
      "epoch: 92, loss: 2.5002500000000003e-05\n",
      "epoch: 93, loss: 2.464630000000001e-05\n",
      "epoch: 94, loss: 2.5338100000000004e-05\n",
      "epoch: 95, loss: 2.4207099999999977e-05\n",
      "epoch: 96, loss: 3.25119e-05\n",
      "epoch: 97, loss: 3.882180000000002e-05\n",
      "epoch: 98, loss: 2.4293499999999977e-05\n",
      "epoch: 99, loss: 2.7094800000000027e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623efba0979d4096b5915a5d1d37500c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.019533339799999997\n",
      "epoch: 1, loss: 0.006491818\n",
      "epoch: 2, loss: 0.0011216677\n",
      "epoch: 3, loss: 0.0010344218999999997\n",
      "epoch: 4, loss: 0.0020965097\n",
      "epoch: 5, loss: 0.0032170062999999994\n",
      "epoch: 6, loss: 0.003317531200000001\n",
      "epoch: 7, loss: 0.0027279555\n",
      "epoch: 8, loss: 0.0019000301\n",
      "epoch: 9, loss: 0.0011898713\n",
      "epoch: 10, loss: 0.0006573495000000002\n",
      "epoch: 11, loss: 0.00031921780000000006\n",
      "epoch: 12, loss: 0.00019944770000000008\n",
      "epoch: 13, loss: 0.0002469127\n",
      "epoch: 14, loss: 0.0003346180000000001\n",
      "epoch: 15, loss: 0.00047011550000000007\n",
      "epoch: 16, loss: 0.0005529999000000002\n",
      "epoch: 17, loss: 0.0006096982\n",
      "epoch: 18, loss: 0.0004862517\n",
      "epoch: 19, loss: 0.0003759732000000001\n",
      "epoch: 20, loss: 0.00033359139999999997\n",
      "epoch: 21, loss: 0.00021058070000000006\n",
      "epoch: 22, loss: 0.0001304719\n",
      "epoch: 23, loss: 9.125400000000006e-05\n",
      "epoch: 24, loss: 7.032030000000001e-05\n",
      "epoch: 25, loss: 5.546839999999996e-05\n",
      "epoch: 26, loss: 5.326580000000003e-05\n",
      "epoch: 27, loss: 5.840700000000005e-05\n",
      "epoch: 28, loss: 7.515899999999999e-05\n",
      "epoch: 29, loss: 7.538179999999995e-05\n",
      "epoch: 30, loss: 8.918319999999996e-05\n",
      "epoch: 31, loss: 7.463329999999996e-05\n",
      "epoch: 32, loss: 6.299459999999999e-05\n",
      "epoch: 33, loss: 6.267270000000002e-05\n",
      "epoch: 34, loss: 5.4080500000000005e-05\n",
      "epoch: 35, loss: 4.3451700000000043e-05\n",
      "epoch: 36, loss: 4.641109999999999e-05\n",
      "epoch: 37, loss: 3.444160000000004e-05\n",
      "epoch: 38, loss: 2.9574199999999924e-05\n",
      "epoch: 39, loss: 4.0456900000000084e-05\n",
      "epoch: 40, loss: 4.784909999999999e-05\n",
      "epoch: 41, loss: 3.81184e-05\n",
      "epoch: 42, loss: 4.971119999999997e-05\n",
      "epoch: 43, loss: 5.265550000000003e-05\n",
      "epoch: 44, loss: 5.0242400000000046e-05\n",
      "epoch: 45, loss: 4.7130399999999985e-05\n",
      "epoch: 46, loss: 4.7200099999999996e-05\n",
      "epoch: 47, loss: 5.753499999999999e-05\n",
      "epoch: 48, loss: 3.714389999999999e-05\n",
      "epoch: 49, loss: 4.5941299999999926e-05\n",
      "epoch: 50, loss: 4.5504499999999964e-05\n",
      "epoch: 51, loss: 3.777960000000004e-05\n",
      "epoch: 52, loss: 3.192679999999998e-05\n",
      "epoch: 53, loss: 3.48547e-05\n",
      "epoch: 54, loss: 2.560189999999999e-05\n",
      "epoch: 55, loss: 3.338970000000005e-05\n",
      "epoch: 56, loss: 2.474569999999996e-05\n",
      "epoch: 57, loss: 3.421049999999996e-05\n",
      "epoch: 58, loss: 3.139279999999999e-05\n",
      "epoch: 59, loss: 3.724029999999997e-05\n",
      "epoch: 60, loss: 2.6279100000000004e-05\n",
      "epoch: 61, loss: 2.9846600000000037e-05\n",
      "epoch: 62, loss: 2.708989999999999e-05\n",
      "epoch: 63, loss: 4.445349999999999e-05\n",
      "epoch: 64, loss: 3.1425799999999966e-05\n",
      "epoch: 65, loss: 3.2824299999999936e-05\n",
      "epoch: 66, loss: 3.020340000000001e-05\n",
      "epoch: 67, loss: 2.981729999999999e-05\n",
      "epoch: 68, loss: 2.920760000000002e-05\n",
      "epoch: 69, loss: 2.776509999999996e-05\n",
      "epoch: 70, loss: 2.2247700000000004e-05\n",
      "epoch: 71, loss: 2.7428100000000016e-05\n",
      "epoch: 72, loss: 2.0101700000000018e-05\n",
      "epoch: 73, loss: 2.236039999999997e-05\n",
      "epoch: 74, loss: 3.10095e-05\n",
      "epoch: 75, loss: 2.9442499999999988e-05\n",
      "epoch: 76, loss: 2.823420000000002e-05\n",
      "epoch: 77, loss: 2.7117000000000005e-05\n",
      "epoch: 78, loss: 3.1051300000000026e-05\n",
      "epoch: 79, loss: 2.4287799999999985e-05\n",
      "epoch: 80, loss: 2.8096699999999924e-05\n",
      "epoch: 81, loss: 2.9270400000000024e-05\n",
      "epoch: 82, loss: 2.9544000000000014e-05\n",
      "epoch: 83, loss: 3.0761300000000006e-05\n",
      "epoch: 84, loss: 2.8455000000000018e-05\n",
      "epoch: 85, loss: 2.0734400000000003e-05\n",
      "epoch: 86, loss: 1.97033e-05\n",
      "epoch: 87, loss: 2.4557500000000003e-05\n",
      "epoch: 88, loss: 3.1397199999999985e-05\n",
      "epoch: 89, loss: 2.9963299999999968e-05\n",
      "epoch: 90, loss: 2.5895000000000022e-05\n",
      "epoch: 91, loss: 2.6948899999999992e-05\n",
      "epoch: 92, loss: 2.627910000000006e-05\n",
      "epoch: 93, loss: 2.9603700000000026e-05\n",
      "epoch: 94, loss: 3.485500000000003e-05\n",
      "epoch: 95, loss: 2.9109699999999997e-05\n",
      "epoch: 96, loss: 3.336759999999999e-05\n",
      "epoch: 97, loss: 2.398730000000003e-05\n",
      "epoch: 98, loss: 3.3649900000000025e-05\n",
      "epoch: 99, loss: 3.215819999999999e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78fabea44be426297643faac294cfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0394932176\n",
      "epoch: 1, loss: 0.021089391800000003\n",
      "epoch: 2, loss: 0.015622379100000002\n",
      "epoch: 3, loss: 0.0133013307\n",
      "epoch: 4, loss: 0.0107872027\n",
      "epoch: 5, loss: 0.0088535031\n",
      "epoch: 6, loss: 0.007459618399999999\n",
      "epoch: 7, loss: 0.006133488\n",
      "epoch: 8, loss: 0.0040665226\n",
      "epoch: 9, loss: 0.0024359032999999998\n",
      "epoch: 10, loss: 0.0013839469000000001\n",
      "epoch: 11, loss: 0.0007557642000000001\n",
      "epoch: 12, loss: 0.0007647717999999999\n",
      "epoch: 13, loss: 0.0009661070999999999\n",
      "epoch: 14, loss: 0.0012532996999999998\n",
      "epoch: 15, loss: 0.0014400346\n",
      "epoch: 16, loss: 0.0015220752999999996\n",
      "epoch: 17, loss: 0.0015424466000000007\n",
      "epoch: 18, loss: 0.0012097434\n",
      "epoch: 19, loss: 0.0009823335000000001\n",
      "epoch: 20, loss: 0.0007517861000000002\n",
      "epoch: 21, loss: 0.0005761583000000001\n",
      "epoch: 22, loss: 0.0003912677000000002\n",
      "epoch: 23, loss: 0.00026950780000000005\n",
      "epoch: 24, loss: 0.00018236289999999991\n",
      "epoch: 25, loss: 0.00016798009999999993\n",
      "epoch: 26, loss: 9.19048e-05\n",
      "epoch: 27, loss: 6.336029999999998e-05\n",
      "epoch: 28, loss: 5.000189999999999e-05\n",
      "epoch: 29, loss: 4.118179999999996e-05\n",
      "epoch: 30, loss: 3.101709999999995e-05\n",
      "epoch: 31, loss: 2.3353499999999982e-05\n",
      "epoch: 32, loss: 2.2724900000000003e-05\n",
      "epoch: 33, loss: 2.8087599999999968e-05\n",
      "epoch: 34, loss: 3.202240000000001e-05\n",
      "epoch: 35, loss: 3.539070000000003e-05\n",
      "epoch: 36, loss: 4.274639999999999e-05\n",
      "epoch: 37, loss: 4.370249999999999e-05\n",
      "epoch: 38, loss: 5.423609999999995e-05\n",
      "epoch: 39, loss: 5.2531299999999996e-05\n",
      "epoch: 40, loss: 7.55016e-05\n",
      "epoch: 41, loss: 7.728530000000001e-05\n",
      "epoch: 42, loss: 7.438159999999999e-05\n",
      "epoch: 43, loss: 7.845619999999998e-05\n",
      "epoch: 44, loss: 8.778339999999994e-05\n",
      "epoch: 45, loss: 7.08107e-05\n",
      "epoch: 46, loss: 8.040379999999998e-05\n",
      "epoch: 47, loss: 7.454969999999995e-05\n",
      "epoch: 48, loss: 8.06349e-05\n",
      "epoch: 49, loss: 7.354150000000001e-05\n",
      "epoch: 50, loss: 5.124989999999999e-05\n",
      "epoch: 51, loss: 5.571689999999999e-05\n",
      "epoch: 52, loss: 5.217010000000002e-05\n",
      "epoch: 53, loss: 5.3253699999999995e-05\n",
      "epoch: 54, loss: 4.910069999999996e-05\n",
      "epoch: 55, loss: 3.793479999999998e-05\n",
      "epoch: 56, loss: 4.47162e-05\n",
      "epoch: 57, loss: 4.475389999999996e-05\n",
      "epoch: 58, loss: 3.555669999999996e-05\n",
      "epoch: 59, loss: 3.396650000000001e-05\n",
      "epoch: 60, loss: 3.225899999999997e-05\n",
      "epoch: 61, loss: 2.22869e-05\n",
      "epoch: 62, loss: 2.4949300000000002e-05\n",
      "epoch: 63, loss: 2.696899999999998e-05\n",
      "epoch: 64, loss: 2.6617200000000037e-05\n",
      "epoch: 65, loss: 2.5855599999999993e-05\n",
      "epoch: 66, loss: 2.5759600000000013e-05\n",
      "epoch: 67, loss: 2.1345999999999985e-05\n",
      "epoch: 68, loss: 2.3928600000000013e-05\n",
      "epoch: 69, loss: 2.4112000000000006e-05\n",
      "epoch: 70, loss: 2.4907400000000008e-05\n",
      "epoch: 71, loss: 2.102759999999998e-05\n",
      "epoch: 72, loss: 2.566000000000004e-05\n",
      "epoch: 73, loss: 3.51541e-05\n",
      "epoch: 74, loss: 2.8163999999999983e-05\n",
      "epoch: 75, loss: 2.329730000000004e-05\n",
      "epoch: 76, loss: 2.0399100000000023e-05\n",
      "epoch: 77, loss: 2.51242e-05\n",
      "epoch: 78, loss: 2.6027399999999987e-05\n",
      "epoch: 79, loss: 2.18614e-05\n",
      "epoch: 80, loss: 2.7460700000000003e-05\n",
      "epoch: 81, loss: 2.3387799999999976e-05\n",
      "epoch: 82, loss: 2.493729999999998e-05\n",
      "epoch: 83, loss: 2.072080000000001e-05\n",
      "epoch: 84, loss: 2.11373e-05\n",
      "epoch: 85, loss: 2.9272500000000005e-05\n",
      "epoch: 86, loss: 2.928699999999993e-05\n",
      "epoch: 87, loss: 2.3216e-05\n",
      "epoch: 88, loss: 2.868060000000003e-05\n",
      "epoch: 89, loss: 2.180620000000004e-05\n",
      "epoch: 90, loss: 1.8268700000000007e-05\n",
      "epoch: 91, loss: 2.9439299999999954e-05\n",
      "epoch: 92, loss: 2.200160000000004e-05\n",
      "epoch: 93, loss: 2.0907500000000006e-05\n",
      "epoch: 94, loss: 2.515319999999999e-05\n",
      "epoch: 95, loss: 2.938200000000003e-05\n",
      "epoch: 96, loss: 3.08039e-05\n",
      "epoch: 97, loss: 2.1670299999999995e-05\n",
      "epoch: 98, loss: 2.7449699999999972e-05\n",
      "epoch: 99, loss: 2.3561799999999995e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7529b06fd94c6c9658d60b953c0be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0065278746\n",
      "epoch: 1, loss: 0.0018993807999999996\n",
      "epoch: 2, loss: 0.0005474757\n",
      "epoch: 3, loss: 0.00013934490000000005\n",
      "epoch: 4, loss: 2.4661400000000028e-05\n",
      "epoch: 5, loss: 2.820980000000002e-05\n",
      "epoch: 6, loss: 3.610519999999999e-05\n",
      "epoch: 7, loss: 4.344770000000004e-05\n",
      "epoch: 8, loss: 6.94012e-05\n",
      "epoch: 9, loss: 0.00011822060000000009\n",
      "epoch: 10, loss: 0.00018988100000000014\n",
      "epoch: 11, loss: 0.00020064040000000009\n",
      "epoch: 12, loss: 0.00026695240000000007\n",
      "epoch: 13, loss: 0.0002673934\n",
      "epoch: 14, loss: 0.00025250170000000005\n",
      "epoch: 15, loss: 0.0002915806\n",
      "epoch: 16, loss: 0.00024993850000000007\n",
      "epoch: 17, loss: 0.00019071260000000007\n",
      "epoch: 18, loss: 0.0001506185\n",
      "epoch: 19, loss: 0.0001047612\n",
      "epoch: 20, loss: 8.974959999999999e-05\n",
      "epoch: 21, loss: 8.823380000000002e-05\n",
      "epoch: 22, loss: 9.898970000000009e-05\n",
      "epoch: 23, loss: 8.695250000000001e-05\n",
      "epoch: 24, loss: 6.645189999999996e-05\n",
      "epoch: 25, loss: 6.82831e-05\n",
      "epoch: 26, loss: 6.065300000000008e-05\n",
      "epoch: 27, loss: 3.807719999999999e-05\n",
      "epoch: 28, loss: 2.590889999999999e-05\n",
      "epoch: 29, loss: 2.918020000000005e-05\n",
      "epoch: 30, loss: 3.296910000000003e-05\n",
      "epoch: 31, loss: 3.621699999999995e-05\n",
      "epoch: 32, loss: 5.021730000000003e-05\n",
      "epoch: 33, loss: 4.288659999999997e-05\n",
      "epoch: 34, loss: 5.427420000000002e-05\n",
      "epoch: 35, loss: 4.8878899999999984e-05\n",
      "epoch: 36, loss: 5.7014399999999926e-05\n",
      "epoch: 37, loss: 4.726390000000002e-05\n",
      "epoch: 38, loss: 3.9419300000000024e-05\n",
      "epoch: 39, loss: 3.514989999999999e-05\n",
      "epoch: 40, loss: 3.8164e-05\n",
      "epoch: 41, loss: 3.345389999999998e-05\n",
      "epoch: 42, loss: 3.523610000000007e-05\n",
      "epoch: 43, loss: 2.6878599999999967e-05\n",
      "epoch: 44, loss: 2.373090000000003e-05\n",
      "epoch: 45, loss: 2.259329999999998e-05\n",
      "epoch: 46, loss: 2.9929800000000026e-05\n",
      "epoch: 47, loss: 2.947550000000002e-05\n",
      "epoch: 48, loss: 3.2987399999999955e-05\n",
      "epoch: 49, loss: 2.0813299999999955e-05\n",
      "epoch: 50, loss: 2.6738499999999968e-05\n",
      "epoch: 51, loss: 2.6531799999999982e-05\n",
      "epoch: 52, loss: 2.015729999999999e-05\n",
      "epoch: 53, loss: 2.8777900000000015e-05\n",
      "epoch: 54, loss: 2.683210000000003e-05\n",
      "epoch: 55, loss: 2.043639999999999e-05\n",
      "epoch: 56, loss: 2.9777800000000015e-05\n",
      "epoch: 57, loss: 2.273939999999998e-05\n",
      "epoch: 58, loss: 2.6446099999999994e-05\n",
      "epoch: 59, loss: 2.3271600000000033e-05\n",
      "epoch: 60, loss: 2.192670000000003e-05\n",
      "epoch: 61, loss: 2.6957599999999987e-05\n",
      "epoch: 62, loss: 2.6666599999999996e-05\n",
      "epoch: 63, loss: 1.903959999999996e-05\n",
      "epoch: 64, loss: 2.2996600000000016e-05\n",
      "epoch: 65, loss: 2.700119999999997e-05\n",
      "epoch: 66, loss: 2.6650099999999964e-05\n",
      "epoch: 67, loss: 2.7031400000000014e-05\n",
      "epoch: 68, loss: 1.8438499999999983e-05\n",
      "epoch: 69, loss: 2.6265100000000007e-05\n",
      "epoch: 70, loss: 2.5402200000000002e-05\n",
      "epoch: 71, loss: 1.7044700000000017e-05\n",
      "epoch: 72, loss: 2.1610700000000006e-05\n",
      "epoch: 73, loss: 3.3550899999999984e-05\n",
      "epoch: 74, loss: 2.4763499999999984e-05\n",
      "epoch: 75, loss: 2.244850000000001e-05\n",
      "epoch: 76, loss: 2.332320000000006e-05\n",
      "epoch: 77, loss: 2.4713500000000007e-05\n",
      "epoch: 78, loss: 3.097180000000002e-05\n",
      "epoch: 79, loss: 2.0995300000000012e-05\n",
      "epoch: 80, loss: 2.9693700000000003e-05\n",
      "epoch: 81, loss: 2.824510000000001e-05\n",
      "epoch: 82, loss: 2.909449999999998e-05\n",
      "epoch: 83, loss: 2.1237900000000005e-05\n",
      "epoch: 84, loss: 2.151020000000001e-05\n",
      "epoch: 85, loss: 3.102799999999999e-05\n",
      "epoch: 86, loss: 3.1758399999999984e-05\n",
      "epoch: 87, loss: 2.3028099999999977e-05\n",
      "epoch: 88, loss: 2.190740000000001e-05\n",
      "epoch: 89, loss: 3.018439999999999e-05\n",
      "epoch: 90, loss: 2.764129999999997e-05\n",
      "epoch: 91, loss: 2.09347e-05\n",
      "epoch: 92, loss: 2.7570300000000006e-05\n",
      "epoch: 93, loss: 2.663270000000003e-05\n",
      "epoch: 94, loss: 2.2565600000000027e-05\n",
      "epoch: 95, loss: 2.375430000000003e-05\n",
      "epoch: 96, loss: 2.3106699999999943e-05\n",
      "epoch: 97, loss: 2.708710000000005e-05\n",
      "epoch: 98, loss: 2.415340000000003e-05\n",
      "epoch: 99, loss: 1.8438200000000002e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109005b42cfb4ee6b84b52a68c31ff55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0008891171000000001\n",
      "epoch: 1, loss: 0.0005792642999999999\n",
      "epoch: 2, loss: 0.00025221850000000013\n",
      "epoch: 3, loss: 0.00022647489999999998\n",
      "epoch: 4, loss: 8.465249999999998e-05\n",
      "epoch: 5, loss: 3.620059999999998e-05\n",
      "epoch: 6, loss: 6.503599999999999e-05\n",
      "epoch: 7, loss: 0.0001061304\n",
      "epoch: 8, loss: 0.00013422760000000004\n",
      "epoch: 9, loss: 0.00011053959999999998\n",
      "epoch: 10, loss: 7.990769999999997e-05\n",
      "epoch: 11, loss: 5.042269999999991e-05\n",
      "epoch: 12, loss: 3.827809999999996e-05\n",
      "epoch: 13, loss: 4.460840000000002e-05\n",
      "epoch: 14, loss: 5.942960000000002e-05\n",
      "epoch: 15, loss: 5.976600000000003e-05\n",
      "epoch: 16, loss: 4.303100000000001e-05\n",
      "epoch: 17, loss: 3.234680000000002e-05\n",
      "epoch: 18, loss: 2.8863299999999985e-05\n",
      "epoch: 19, loss: 2.4187800000000026e-05\n",
      "epoch: 20, loss: 2.4041900000000008e-05\n",
      "epoch: 21, loss: 2.734859999999999e-05\n",
      "epoch: 22, loss: 3.2732200000000005e-05\n",
      "epoch: 23, loss: 2.7640399999999977e-05\n",
      "epoch: 24, loss: 2.9405200000000015e-05\n",
      "epoch: 25, loss: 3.035389999999997e-05\n",
      "epoch: 26, loss: 2.967289999999999e-05\n",
      "epoch: 27, loss: 3.3737400000000013e-05\n",
      "epoch: 28, loss: 3.2998700000000006e-05\n",
      "epoch: 29, loss: 2.5741800000000035e-05\n",
      "epoch: 30, loss: 2.4842300000000008e-05\n",
      "epoch: 31, loss: 2.529270000000001e-05\n",
      "epoch: 32, loss: 2.747690000000002e-05\n",
      "epoch: 33, loss: 2.051260000000002e-05\n",
      "epoch: 34, loss: 2.5924499999999982e-05\n",
      "epoch: 35, loss: 2.196240000000001e-05\n",
      "epoch: 36, loss: 2.7038899999999966e-05\n",
      "epoch: 37, loss: 2.8441199999999974e-05\n",
      "epoch: 38, loss: 2.197959999999999e-05\n",
      "epoch: 39, loss: 2.2405000000000003e-05\n",
      "epoch: 40, loss: 2.164839999999995e-05\n",
      "epoch: 41, loss: 2.4722799999999986e-05\n",
      "epoch: 42, loss: 2.1028100000000013e-05\n",
      "epoch: 43, loss: 2.4878000000000015e-05\n",
      "epoch: 44, loss: 2.392759999999999e-05\n",
      "epoch: 45, loss: 2.4303300000000032e-05\n",
      "epoch: 46, loss: 2.459369999999997e-05\n",
      "epoch: 47, loss: 2.9257900000000003e-05\n",
      "epoch: 48, loss: 2.6142699999999993e-05\n",
      "epoch: 49, loss: 2.3517400000000033e-05\n",
      "epoch: 50, loss: 2.1841200000000007e-05\n",
      "epoch: 51, loss: 2.6924900000000034e-05\n",
      "epoch: 52, loss: 3.442490000000003e-05\n",
      "epoch: 53, loss: 2.2234699999999992e-05\n",
      "epoch: 54, loss: 2.3100199999999993e-05\n",
      "epoch: 55, loss: 2.1513199999999965e-05\n",
      "epoch: 56, loss: 2.559780000000001e-05\n",
      "epoch: 57, loss: 2.82985e-05\n",
      "epoch: 58, loss: 3.9280900000000005e-05\n",
      "epoch: 59, loss: 2.5339100000000013e-05\n",
      "epoch: 60, loss: 2.720299999999994e-05\n",
      "epoch: 61, loss: 2.2258999999999998e-05\n",
      "epoch: 62, loss: 1.743630000000001e-05\n",
      "epoch: 63, loss: 2.8247299999999962e-05\n",
      "epoch: 64, loss: 1.84547e-05\n",
      "epoch: 65, loss: 2.329740000000001e-05\n",
      "epoch: 66, loss: 2.079940000000001e-05\n",
      "epoch: 67, loss: 2.229459999999998e-05\n",
      "epoch: 68, loss: 2.4649699999999972e-05\n",
      "epoch: 69, loss: 2.5170299999999958e-05\n",
      "epoch: 70, loss: 2.2699200000000025e-05\n",
      "epoch: 71, loss: 2.3403499999999977e-05\n",
      "epoch: 72, loss: 2.71158e-05\n",
      "epoch: 73, loss: 2.2959599999999993e-05\n",
      "epoch: 74, loss: 2.4143000000000043e-05\n",
      "epoch: 75, loss: 3.2810799999999994e-05\n",
      "epoch: 76, loss: 3.668599999999996e-05\n",
      "epoch: 77, loss: 2.32524e-05\n",
      "epoch: 78, loss: 2.6315000000000015e-05\n",
      "epoch: 79, loss: 2.8463000000000015e-05\n",
      "epoch: 80, loss: 2.734179999999997e-05\n",
      "epoch: 81, loss: 2.3285199999999958e-05\n",
      "epoch: 82, loss: 2.7283500000000034e-05\n",
      "epoch: 83, loss: 2.5956499999999934e-05\n",
      "epoch: 84, loss: 2.4114600000000015e-05\n",
      "epoch: 85, loss: 2.750449999999999e-05\n",
      "epoch: 86, loss: 2.8833699999999988e-05\n",
      "epoch: 87, loss: 2.7158099999999987e-05\n",
      "epoch: 88, loss: 2.546139999999999e-05\n",
      "epoch: 89, loss: 2.649e-05\n",
      "epoch: 90, loss: 2.615909999999998e-05\n",
      "epoch: 91, loss: 2.432809999999999e-05\n",
      "epoch: 92, loss: 2.7314099999999997e-05\n",
      "epoch: 93, loss: 2.5117600000000025e-05\n",
      "epoch: 94, loss: 2.4163800000000014e-05\n",
      "epoch: 95, loss: 2.782729999999999e-05\n",
      "epoch: 96, loss: 2.5557700000000025e-05\n",
      "epoch: 97, loss: 2.074400000000006e-05\n",
      "epoch: 98, loss: 2.686219999999998e-05\n",
      "epoch: 99, loss: 2.2198099999999987e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c602c868ab394d9ab1f75f82148eaeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.022383091600000002\n",
      "epoch: 1, loss: 0.0057851753\n",
      "epoch: 2, loss: 0.0007370993000000002\n",
      "epoch: 3, loss: 0.0025468299\n",
      "epoch: 4, loss: 0.0054612905\n",
      "epoch: 5, loss: 0.005528915499999999\n",
      "epoch: 6, loss: 0.0038385923\n",
      "epoch: 7, loss: 0.0022911413\n",
      "epoch: 8, loss: 0.0019545425\n",
      "epoch: 9, loss: 0.002224085\n",
      "epoch: 10, loss: 0.002672538699999999\n",
      "epoch: 11, loss: 0.0028318395000000002\n",
      "epoch: 12, loss: 0.0025746097000000005\n",
      "epoch: 13, loss: 0.002276081\n",
      "epoch: 14, loss: 0.0019305328999999999\n",
      "epoch: 15, loss: 0.0014900056\n",
      "epoch: 16, loss: 0.0012178719000000002\n",
      "epoch: 17, loss: 0.0012671128999999998\n",
      "epoch: 18, loss: 0.0015210112000000001\n",
      "epoch: 19, loss: 0.0017004528\n",
      "epoch: 20, loss: 0.0017281000999999998\n",
      "epoch: 21, loss: 0.0015447835999999999\n",
      "epoch: 22, loss: 0.0013410554\n",
      "epoch: 23, loss: 0.0010602377000000001\n",
      "epoch: 24, loss: 0.0008179143000000001\n",
      "epoch: 25, loss: 0.0008495616000000001\n",
      "epoch: 26, loss: 0.0008161004\n",
      "epoch: 27, loss: 0.0008753455999999998\n",
      "epoch: 28, loss: 0.0009031278999999999\n",
      "epoch: 29, loss: 0.0008638490999999999\n",
      "epoch: 30, loss: 0.0007423795\n",
      "epoch: 31, loss: 0.0005946041\n",
      "epoch: 32, loss: 0.0005139661000000001\n",
      "epoch: 33, loss: 0.0004901835\n",
      "epoch: 34, loss: 0.00048672620000000006\n",
      "epoch: 35, loss: 0.0004935111999999999\n",
      "epoch: 36, loss: 0.00046654749999999984\n",
      "epoch: 37, loss: 0.0004375172\n",
      "epoch: 38, loss: 0.00036801539999999994\n",
      "epoch: 39, loss: 0.00034297270000000006\n",
      "epoch: 40, loss: 0.00029835150000000004\n",
      "epoch: 41, loss: 0.00026720570000000004\n",
      "epoch: 42, loss: 0.0002787664\n",
      "epoch: 43, loss: 0.0002601195\n",
      "epoch: 44, loss: 0.00025285990000000006\n",
      "epoch: 45, loss: 0.00023956909999999984\n",
      "epoch: 46, loss: 0.00022716179999999992\n",
      "epoch: 47, loss: 0.0002044386000000001\n",
      "epoch: 48, loss: 0.00018245200000000002\n",
      "epoch: 49, loss: 0.00020330489999999992\n",
      "epoch: 50, loss: 0.00017898210000000012\n",
      "epoch: 51, loss: 0.00016112250000000012\n",
      "epoch: 52, loss: 0.00014155089999999993\n",
      "epoch: 53, loss: 0.00015217729999999997\n",
      "epoch: 54, loss: 0.00014620669999999998\n",
      "epoch: 55, loss: 0.00012981170000000004\n",
      "epoch: 56, loss: 0.00010526029999999997\n",
      "epoch: 57, loss: 0.00012074239999999994\n",
      "epoch: 58, loss: 0.00011580260000000006\n",
      "epoch: 59, loss: 9.896829999999992e-05\n",
      "epoch: 60, loss: 9.260899999999994e-05\n",
      "epoch: 61, loss: 0.0001037108\n",
      "epoch: 62, loss: 8.078189999999997e-05\n",
      "epoch: 63, loss: 7.753929999999998e-05\n",
      "epoch: 64, loss: 8.42657e-05\n",
      "epoch: 65, loss: 7.0867e-05\n",
      "epoch: 66, loss: 7.60649e-05\n",
      "epoch: 67, loss: 6.395590000000007e-05\n",
      "epoch: 68, loss: 6.312169999999995e-05\n",
      "epoch: 69, loss: 6.521449999999998e-05\n",
      "epoch: 70, loss: 5.679730000000002e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-59003cf7a42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          lr = 0.1)\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mqnn_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, epochs, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, samplewise, include_loss)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             weight_gradient, delta = layer.grad(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 self.a[i], delta, samplewise=samplewise)\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_gradient_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/layers.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, inputs, delta, samplewise)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0minput_partial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0minput_partial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcircuit_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_1_constant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_2_constant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 3, 1],\n",
    "                         lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=1000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_constant\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.3, 0.02) - gaussian(x, 0.7, 0.02) \n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0.1, b=0.9)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 3, 1],\n",
    "                         lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=1000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 10\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.75]])\n",
    "var1 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean2 = np.array([[0.75, 0.25]])\n",
    "var2 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean3 = np.array([[0.25, 0.25]])\n",
    "var3 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean4 = np.array([[0.75, 0.75]])\n",
    "var4 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var1) + gaussian(x, mean2, var2) - gaussian(x, mean3, var3) - gaussian(x, mean4, var4)\n",
    "\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61018c877ff344cca69036349bc4ac58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a357b9a86842e3b4ccbb29e6b9b386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 3,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 6, 1],\n",
    "                     lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=5000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 5\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0.1, b=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()\n",
    "print(y.reshape(n,n,n)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(1):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(1):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(1):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 3,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(1):\n",
    "    dnn = sequential_dnn(dim = [3, 10, 10, 1],\n",
    "                     lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=5000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
