{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Constant Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = 0.5*np.ones((n,1))\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_1_constant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_2_constant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 3, 1],\n",
    "                         lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=1000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_constant\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.3, 0.02) - gaussian(x, 0.7, 0.02) \n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0.1, b=0.9)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [1, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         lr = 0.1)\n",
    "    \n",
    "    dnn.train(x, y, epochs=1000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 10\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.75]])\n",
    "var1 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean2 = np.array([[0.75, 0.25]])\n",
    "var2 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean3 = np.array([[0.25, 0.25]])\n",
    "var3 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "mean4 = np.array([[0.75, 0.75]])\n",
    "var4 = np.array([[0.02, 0], [0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var1) + gaussian(x, mean2, var2) - gaussian(x, mean3, var3) - gaussian(x, mean4, var4)\n",
    "\n",
    "\n",
    "x_qnn = scaler(x, a=0, b=np.pi)\n",
    "x_dnn = (x - np.mean(x, axis=0))/np.std(x, axis=0)\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef781e2d4364b4797e7ad9822f11819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8147c97bf4aaaaebdc959a2a96d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09586317905625538\n",
      "epoch: 1, loss: 0.05656953260454042\n",
      "epoch: 2, loss: 0.04688701516006895\n",
      "epoch: 3, loss: 0.047755678048540445\n",
      "epoch: 4, loss: 0.04486530111115115\n",
      "epoch: 5, loss: 0.04006747157302971\n",
      "epoch: 6, loss: 0.03826027767225782\n",
      "epoch: 7, loss: 0.0376505806456495\n",
      "epoch: 8, loss: 0.03571657504752377\n",
      "epoch: 9, loss: 0.03291808645465852\n",
      "epoch: 10, loss: 0.030872570259788987\n",
      "epoch: 11, loss: 0.030649154219042796\n",
      "epoch: 12, loss: 0.03099287564660433\n",
      "epoch: 13, loss: 0.03200529030464381\n",
      "epoch: 14, loss: 0.032599922986091566\n",
      "epoch: 15, loss: 0.03205172957951995\n",
      "epoch: 16, loss: 0.03224787692950825\n",
      "epoch: 17, loss: 0.032039289352025026\n",
      "epoch: 18, loss: 0.030771870706771433\n",
      "epoch: 19, loss: 0.02978678201759317\n",
      "epoch: 20, loss: 0.028892952793944337\n",
      "epoch: 21, loss: 0.02790872384679704\n",
      "epoch: 22, loss: 0.027511141575472825\n",
      "epoch: 23, loss: 0.02686722557794921\n",
      "epoch: 24, loss: 0.02730517500190881\n",
      "epoch: 25, loss: 0.02752113103794897\n",
      "epoch: 26, loss: 0.026548040017878832\n",
      "epoch: 27, loss: 0.027343209379710003\n",
      "epoch: 28, loss: 0.026725032315667877\n",
      "epoch: 29, loss: 0.026860871398666795\n",
      "epoch: 30, loss: 0.027176858602648835\n",
      "epoch: 31, loss: 0.026993664523413497\n",
      "epoch: 32, loss: 0.02661068121808891\n",
      "epoch: 33, loss: 0.026234775013686665\n",
      "epoch: 34, loss: 0.02729708607795781\n",
      "epoch: 35, loss: 0.026891566937798782\n",
      "epoch: 36, loss: 0.026922862109723045\n",
      "epoch: 37, loss: 0.026716326567179583\n",
      "epoch: 38, loss: 0.02657063018801996\n",
      "epoch: 39, loss: 0.026120950305544146\n",
      "epoch: 40, loss: 0.02615322921439229\n",
      "epoch: 41, loss: 0.02587012935395294\n",
      "epoch: 42, loss: 0.02566033749972886\n",
      "epoch: 43, loss: 0.025948178533324616\n",
      "epoch: 44, loss: 0.02557143249895308\n",
      "epoch: 45, loss: 0.026196471174420748\n",
      "epoch: 46, loss: 0.026084625937833512\n",
      "epoch: 47, loss: 0.025972117176988364\n",
      "epoch: 48, loss: 0.02562188474089884\n",
      "epoch: 49, loss: 0.02619829673278915\n",
      "epoch: 50, loss: 0.02655214054168701\n",
      "epoch: 51, loss: 0.026128655322807143\n",
      "epoch: 52, loss: 0.025484933103768447\n",
      "epoch: 53, loss: 0.025918584217642593\n",
      "epoch: 54, loss: 0.026156916654737142\n",
      "epoch: 55, loss: 0.0255613165902755\n",
      "epoch: 56, loss: 0.02576330753775867\n",
      "epoch: 57, loss: 0.026046685616677338\n",
      "epoch: 58, loss: 0.026090216604343595\n",
      "epoch: 59, loss: 0.025699379824016898\n",
      "epoch: 60, loss: 0.02550944264695933\n",
      "epoch: 61, loss: 0.025862547407864988\n",
      "epoch: 62, loss: 0.026323245402553628\n",
      "epoch: 63, loss: 0.026273574225272975\n",
      "epoch: 64, loss: 0.025892309681076316\n",
      "epoch: 65, loss: 0.02569593123491021\n",
      "epoch: 66, loss: 0.025710958274139162\n",
      "epoch: 67, loss: 0.02576307839581844\n",
      "epoch: 68, loss: 0.02569152645744085\n",
      "epoch: 69, loss: 0.02562720945012839\n",
      "epoch: 70, loss: 0.02511342956444229\n",
      "epoch: 71, loss: 0.025587543415866425\n",
      "epoch: 72, loss: 0.026109147286582868\n",
      "epoch: 73, loss: 0.025661719820102\n",
      "epoch: 74, loss: 0.025214228849422732\n",
      "epoch: 75, loss: 0.025632283299767935\n",
      "epoch: 76, loss: 0.025649324781928648\n",
      "epoch: 77, loss: 0.025991601186702313\n",
      "epoch: 78, loss: 0.02601089661491583\n",
      "epoch: 79, loss: 0.02548596663267866\n",
      "epoch: 80, loss: 0.02553702121256121\n",
      "epoch: 81, loss: 0.02535055554863318\n",
      "epoch: 82, loss: 0.025771331133281637\n",
      "epoch: 83, loss: 0.025676770793486133\n",
      "epoch: 84, loss: 0.02579401741458592\n",
      "epoch: 85, loss: 0.02548177704491777\n",
      "epoch: 86, loss: 0.025870700721886145\n",
      "epoch: 87, loss: 0.025588236627712622\n",
      "epoch: 88, loss: 0.02529708526884823\n",
      "epoch: 89, loss: 0.025712578630927508\n",
      "epoch: 90, loss: 0.025276921284095314\n",
      "epoch: 91, loss: 0.02598225401779906\n",
      "epoch: 92, loss: 0.025962112314010778\n",
      "epoch: 93, loss: 0.025569282723009526\n",
      "epoch: 94, loss: 0.025341585803092162\n",
      "epoch: 95, loss: 0.025973844403929247\n",
      "epoch: 96, loss: 0.025639202995873425\n",
      "epoch: 97, loss: 0.025527937842205025\n",
      "epoch: 98, loss: 0.025313099561648702\n",
      "epoch: 99, loss: 0.025790351028429415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c369bf5910404c7dbc9e9fd8eac15a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.11496378135429416\n",
      "epoch: 1, loss: 0.08676129215490713\n",
      "epoch: 2, loss: 0.07078895680209361\n",
      "epoch: 3, loss: 0.064143562975283\n",
      "epoch: 4, loss: 0.0585000834935635\n",
      "epoch: 5, loss: 0.052724836185928395\n",
      "epoch: 6, loss: 0.04726012313256143\n",
      "epoch: 7, loss: 0.04276074582689757\n",
      "epoch: 8, loss: 0.037170361105434584\n",
      "epoch: 9, loss: 0.03281220315870293\n",
      "epoch: 10, loss: 0.028397679677904897\n",
      "epoch: 11, loss: 0.02548812697240532\n",
      "epoch: 12, loss: 0.02253752315047881\n",
      "epoch: 13, loss: 0.019312499929008436\n",
      "epoch: 14, loss: 0.017529882461043048\n",
      "epoch: 15, loss: 0.018893817722567045\n",
      "epoch: 16, loss: 0.020016697694964673\n",
      "epoch: 17, loss: 0.01975636518506897\n",
      "epoch: 18, loss: 0.01860475051590328\n",
      "epoch: 19, loss: 0.015937230315332514\n",
      "epoch: 20, loss: 0.014165942240119498\n",
      "epoch: 21, loss: 0.013259879313951693\n",
      "epoch: 22, loss: 0.012849919537023094\n",
      "epoch: 23, loss: 0.01192141693569994\n",
      "epoch: 24, loss: 0.011955728223593974\n",
      "epoch: 25, loss: 0.01168508844488265\n",
      "epoch: 26, loss: 0.012994203886010514\n",
      "epoch: 27, loss: 0.013478625321543689\n",
      "epoch: 28, loss: 0.013806358241330944\n",
      "epoch: 29, loss: 0.013441476169594456\n",
      "epoch: 30, loss: 0.012763055045133998\n",
      "epoch: 31, loss: 0.011890677546092883\n",
      "epoch: 32, loss: 0.011659842808266294\n",
      "epoch: 33, loss: 0.01154393139164529\n",
      "epoch: 34, loss: 0.01172316534962243\n",
      "epoch: 35, loss: 0.011953173210404558\n",
      "epoch: 36, loss: 0.011751272440175011\n",
      "epoch: 37, loss: 0.011746330814955838\n",
      "epoch: 38, loss: 0.011758339120927967\n",
      "epoch: 39, loss: 0.012054844178210178\n",
      "epoch: 40, loss: 0.011777224128519172\n",
      "epoch: 41, loss: 0.011146905503729113\n",
      "epoch: 42, loss: 0.011146058209532789\n",
      "epoch: 43, loss: 0.010673071188988137\n",
      "epoch: 44, loss: 0.010816259764420515\n",
      "epoch: 45, loss: 0.011043390806921112\n",
      "epoch: 46, loss: 0.010947635593324819\n",
      "epoch: 47, loss: 0.0114695937522472\n",
      "epoch: 48, loss: 0.01105266025772204\n",
      "epoch: 49, loss: 0.011138802631144003\n",
      "epoch: 50, loss: 0.011193116557164555\n",
      "epoch: 51, loss: 0.010948399578463032\n",
      "epoch: 52, loss: 0.010950662170567662\n",
      "epoch: 53, loss: 0.010846930701952529\n",
      "epoch: 54, loss: 0.010786329178886007\n",
      "epoch: 55, loss: 0.010431354016283353\n",
      "epoch: 56, loss: 0.010800885315703597\n",
      "epoch: 57, loss: 0.011072536870187525\n",
      "epoch: 58, loss: 0.01093457093990231\n",
      "epoch: 59, loss: 0.010748704577141457\n",
      "epoch: 60, loss: 0.010718936080488729\n",
      "epoch: 61, loss: 0.01101319670603484\n",
      "epoch: 62, loss: 0.010825198701236126\n",
      "epoch: 63, loss: 0.010656233459321788\n",
      "epoch: 64, loss: 0.010349931409049402\n",
      "epoch: 65, loss: 0.010781123287938904\n",
      "epoch: 66, loss: 0.010689782787991342\n",
      "epoch: 67, loss: 0.01086009217625125\n",
      "epoch: 68, loss: 0.010500254118143384\n",
      "epoch: 69, loss: 0.010695235840266848\n",
      "epoch: 70, loss: 0.010450141228473724\n",
      "epoch: 71, loss: 0.010646653600524596\n",
      "epoch: 72, loss: 0.01039641205838267\n",
      "epoch: 73, loss: 0.010211962246951116\n",
      "epoch: 74, loss: 0.010974617859129406\n",
      "epoch: 75, loss: 0.010391885942311512\n",
      "epoch: 76, loss: 0.010503229120676664\n",
      "epoch: 77, loss: 0.010865646159409563\n",
      "epoch: 78, loss: 0.010858328349701072\n",
      "epoch: 79, loss: 0.010272821494019013\n",
      "epoch: 80, loss: 0.010300230687754408\n",
      "epoch: 81, loss: 0.010920193310209747\n",
      "epoch: 82, loss: 0.010509315470386247\n",
      "epoch: 83, loss: 0.010482357733576239\n",
      "epoch: 84, loss: 0.010794512685572582\n",
      "epoch: 85, loss: 0.01077062984050473\n",
      "epoch: 86, loss: 0.010581956133672616\n",
      "epoch: 87, loss: 0.010705953581342225\n",
      "epoch: 88, loss: 0.010537743839316526\n",
      "epoch: 89, loss: 0.010602363025040524\n",
      "epoch: 90, loss: 0.010245801535358843\n",
      "epoch: 91, loss: 0.010334474940698118\n",
      "epoch: 92, loss: 0.010564605559831367\n",
      "epoch: 93, loss: 0.010592475367351372\n",
      "epoch: 94, loss: 0.010226159146829424\n",
      "epoch: 95, loss: 0.010577739576643243\n",
      "epoch: 96, loss: 0.010521821473525792\n",
      "epoch: 97, loss: 0.010806813437425426\n",
      "epoch: 98, loss: 0.010786176924841453\n",
      "epoch: 99, loss: 0.010327664076505679\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9ef220a9db4a35a96c7415f1a386fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.04424906671827487\n",
      "epoch: 1, loss: 0.032145249900173846\n",
      "epoch: 2, loss: 0.027615176752381967\n",
      "epoch: 3, loss: 0.024727990432720833\n",
      "epoch: 4, loss: 0.021175541138795283\n",
      "epoch: 5, loss: 0.02021503517725923\n",
      "epoch: 6, loss: 0.020426212609595446\n",
      "epoch: 7, loss: 0.01938251337259296\n",
      "epoch: 8, loss: 0.019263508587704353\n",
      "epoch: 9, loss: 0.019567564916929805\n",
      "epoch: 10, loss: 0.019362771637605445\n",
      "epoch: 11, loss: 0.019438122256854894\n",
      "epoch: 12, loss: 0.019726359216410874\n",
      "epoch: 13, loss: 0.0198504194849329\n",
      "epoch: 14, loss: 0.01955037028120325\n",
      "epoch: 15, loss: 0.019116428314692104\n",
      "epoch: 16, loss: 0.0188295848986712\n",
      "epoch: 17, loss: 0.018456879027607915\n",
      "epoch: 18, loss: 0.01778175623496988\n",
      "epoch: 19, loss: 0.01754909062760922\n",
      "epoch: 20, loss: 0.01706309469388007\n",
      "epoch: 21, loss: 0.016426239100312875\n",
      "epoch: 22, loss: 0.01596478817933225\n",
      "epoch: 23, loss: 0.015430084792874737\n",
      "epoch: 24, loss: 0.014821925609331122\n",
      "epoch: 25, loss: 0.014466839527624776\n",
      "epoch: 26, loss: 0.013653827835777685\n",
      "epoch: 27, loss: 0.01319804365257646\n",
      "epoch: 28, loss: 0.013175279220345696\n",
      "epoch: 29, loss: 0.012749097779893281\n",
      "epoch: 30, loss: 0.012528396975120032\n",
      "epoch: 31, loss: 0.012173616978332977\n",
      "epoch: 32, loss: 0.012394619578132163\n",
      "epoch: 33, loss: 0.012118540118283606\n",
      "epoch: 34, loss: 0.012185596594692817\n",
      "epoch: 35, loss: 0.012016497431856128\n",
      "epoch: 36, loss: 0.011829337225246584\n",
      "epoch: 37, loss: 0.011887437297032968\n",
      "epoch: 38, loss: 0.01166822567535854\n",
      "epoch: 39, loss: 0.01122034980631352\n",
      "epoch: 40, loss: 0.011548519364233062\n",
      "epoch: 41, loss: 0.011213363464001149\n",
      "epoch: 42, loss: 0.01128061843451828\n",
      "epoch: 43, loss: 0.011229625096539764\n",
      "epoch: 44, loss: 0.010661606887433245\n",
      "epoch: 45, loss: 0.010966732311233528\n",
      "epoch: 46, loss: 0.010499894695716511\n",
      "epoch: 47, loss: 0.010551585384736297\n",
      "epoch: 48, loss: 0.010393550042606921\n",
      "epoch: 49, loss: 0.010391281401823469\n",
      "epoch: 50, loss: 0.010291640584410464\n",
      "epoch: 51, loss: 0.009716910219375392\n",
      "epoch: 52, loss: 0.010015439442623897\n",
      "epoch: 53, loss: 0.009732644398468054\n",
      "epoch: 54, loss: 0.009541016360402974\n",
      "epoch: 55, loss: 0.009584074559219063\n",
      "epoch: 56, loss: 0.009709822732743303\n",
      "epoch: 57, loss: 0.009717957523433235\n",
      "epoch: 58, loss: 0.0091955766678829\n",
      "epoch: 59, loss: 0.009452580509304032\n",
      "epoch: 60, loss: 0.009741885103025455\n",
      "epoch: 61, loss: 0.009766911280129463\n",
      "epoch: 62, loss: 0.009442364616895646\n",
      "epoch: 63, loss: 0.009264046539965628\n",
      "epoch: 64, loss: 0.009585638303981353\n",
      "epoch: 65, loss: 0.009598304488416287\n",
      "epoch: 66, loss: 0.009628039033930346\n",
      "epoch: 67, loss: 0.009573346612860842\n",
      "epoch: 68, loss: 0.009556703105667504\n",
      "epoch: 69, loss: 0.00918384683143143\n",
      "epoch: 70, loss: 0.009690026349028068\n",
      "epoch: 71, loss: 0.009503429795150401\n",
      "epoch: 72, loss: 0.00928844067248501\n",
      "epoch: 73, loss: 0.009265421413440451\n",
      "epoch: 74, loss: 0.009362639276710931\n",
      "epoch: 75, loss: 0.009463106134384865\n",
      "epoch: 76, loss: 0.009468489474828135\n",
      "epoch: 77, loss: 0.00934005843228727\n",
      "epoch: 78, loss: 0.00938889176855856\n",
      "epoch: 79, loss: 0.009024712303181477\n",
      "epoch: 80, loss: 0.009490752810058461\n",
      "epoch: 81, loss: 0.009275939149030587\n",
      "epoch: 82, loss: 0.009119263684586112\n",
      "epoch: 83, loss: 0.009485891655655563\n",
      "epoch: 84, loss: 0.009501594404100606\n",
      "epoch: 85, loss: 0.009291646468050562\n",
      "epoch: 86, loss: 0.009372911904299846\n",
      "epoch: 87, loss: 0.009175190525256826\n",
      "epoch: 88, loss: 0.009280101839902051\n",
      "epoch: 89, loss: 0.009116977340781667\n",
      "epoch: 90, loss: 0.009289909546389917\n",
      "epoch: 91, loss: 0.009597648362917158\n",
      "epoch: 92, loss: 0.009372789190602769\n",
      "epoch: 93, loss: 0.00922211690015525\n",
      "epoch: 94, loss: 0.009163946009782719\n",
      "epoch: 95, loss: 0.009671905840468792\n",
      "epoch: 96, loss: 0.009493471693104386\n",
      "epoch: 97, loss: 0.009575338080595991\n",
      "epoch: 98, loss: 0.009396122978607306\n",
      "epoch: 99, loss: 0.00953105762054572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789fc2e99eac4029ac470e334a0e2b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.05414902996591184\n",
      "epoch: 1, loss: 0.048769311963035994\n",
      "epoch: 2, loss: 0.04621691637470064\n",
      "epoch: 3, loss: 0.04420806733064701\n",
      "epoch: 4, loss: 0.041313180110018485\n",
      "epoch: 5, loss: 0.038780804639037464\n",
      "epoch: 6, loss: 0.035655361741684974\n",
      "epoch: 7, loss: 0.032819863448892816\n",
      "epoch: 8, loss: 0.029334499597718132\n",
      "epoch: 9, loss: 0.025582412797931754\n",
      "epoch: 10, loss: 0.021295469335984266\n",
      "epoch: 11, loss: 0.018284256603641583\n",
      "epoch: 12, loss: 0.01585186317589909\n",
      "epoch: 13, loss: 0.014769994095521866\n",
      "epoch: 14, loss: 0.014049292510062346\n",
      "epoch: 15, loss: 0.0138377766865014\n",
      "epoch: 16, loss: 0.012852853153430868\n",
      "epoch: 17, loss: 0.011626084924072952\n",
      "epoch: 18, loss: 0.010780375009644426\n",
      "epoch: 19, loss: 0.010852580668404667\n",
      "epoch: 20, loss: 0.010521190857684857\n",
      "epoch: 21, loss: 0.010616659647044413\n",
      "epoch: 22, loss: 0.010714166394280886\n",
      "epoch: 23, loss: 0.011246785332157495\n",
      "epoch: 24, loss: 0.01113854865447696\n",
      "epoch: 25, loss: 0.01136280759464148\n",
      "epoch: 26, loss: 0.011356348256678538\n",
      "epoch: 27, loss: 0.011199158544058922\n",
      "epoch: 28, loss: 0.011596520998835484\n",
      "epoch: 29, loss: 0.010800893368732524\n",
      "epoch: 30, loss: 0.011182674244896993\n",
      "epoch: 31, loss: 0.010761071485412015\n",
      "epoch: 32, loss: 0.010344399535160576\n",
      "epoch: 33, loss: 0.010482453878841702\n",
      "epoch: 34, loss: 0.010235619683189813\n",
      "epoch: 35, loss: 0.010186003748008392\n",
      "epoch: 36, loss: 0.010693632163887745\n",
      "epoch: 37, loss: 0.010301105944817536\n",
      "epoch: 38, loss: 0.010191927973462887\n",
      "epoch: 39, loss: 0.010247280752993537\n",
      "epoch: 40, loss: 0.010222579132120128\n",
      "epoch: 41, loss: 0.010102445865934662\n",
      "epoch: 42, loss: 0.010075226161624914\n",
      "epoch: 43, loss: 0.009820453874104946\n",
      "epoch: 44, loss: 0.009880502045291199\n",
      "epoch: 45, loss: 0.010169953049322382\n",
      "epoch: 46, loss: 0.009749848817036168\n",
      "epoch: 47, loss: 0.009812002299831106\n",
      "epoch: 48, loss: 0.00998455054138644\n",
      "epoch: 49, loss: 0.01002618969573302\n",
      "epoch: 50, loss: 0.010081654878262463\n",
      "epoch: 51, loss: 0.010011346869857203\n",
      "epoch: 52, loss: 0.010128667732763313\n",
      "epoch: 53, loss: 0.009518674347469044\n",
      "epoch: 54, loss: 0.010017892010229717\n",
      "epoch: 55, loss: 0.009609784804188094\n",
      "epoch: 56, loss: 0.009852276685884308\n",
      "epoch: 57, loss: 0.009800741024960565\n",
      "epoch: 58, loss: 0.009797177803125074\n",
      "epoch: 59, loss: 0.010078553749097871\n",
      "epoch: 60, loss: 0.009936540517257736\n",
      "epoch: 61, loss: 0.00978413343258921\n",
      "epoch: 62, loss: 0.009742715640030854\n",
      "epoch: 63, loss: 0.009679578293741659\n",
      "epoch: 64, loss: 0.009380929576577978\n",
      "epoch: 65, loss: 0.009611143118227014\n",
      "epoch: 66, loss: 0.009650185700551232\n",
      "epoch: 67, loss: 0.009909914356777181\n",
      "epoch: 68, loss: 0.009632630226936835\n",
      "epoch: 69, loss: 0.009862446604510355\n",
      "epoch: 70, loss: 0.009689599250953036\n",
      "epoch: 71, loss: 0.009644537813364884\n",
      "epoch: 72, loss: 0.009394098086826343\n",
      "epoch: 73, loss: 0.009872304873284565\n",
      "epoch: 74, loss: 0.0096818964420456\n",
      "epoch: 75, loss: 0.009846795640228388\n",
      "epoch: 76, loss: 0.009553396751303006\n",
      "epoch: 77, loss: 0.009684199681633676\n",
      "epoch: 78, loss: 0.00987378866644532\n",
      "epoch: 79, loss: 0.009583965948027313\n",
      "epoch: 80, loss: 0.009914919379709364\n",
      "epoch: 81, loss: 0.009855628856132514\n",
      "epoch: 82, loss: 0.010054474905945436\n",
      "epoch: 83, loss: 0.009954681354865129\n",
      "epoch: 84, loss: 0.00973957202335295\n",
      "epoch: 85, loss: 0.009685827196799682\n",
      "epoch: 86, loss: 0.009819505600645023\n",
      "epoch: 87, loss: 0.009654965988144023\n",
      "epoch: 88, loss: 0.010168886133453547\n",
      "epoch: 89, loss: 0.009721109348668908\n",
      "epoch: 90, loss: 0.009931761219463977\n",
      "epoch: 91, loss: 0.010038684812257866\n",
      "epoch: 92, loss: 0.009684352751338637\n",
      "epoch: 93, loss: 0.009617842882707723\n",
      "epoch: 94, loss: 0.009649898509657698\n",
      "epoch: 95, loss: 0.009868024353262235\n",
      "epoch: 96, loss: 0.009909063618352629\n",
      "epoch: 97, loss: 0.009644501856315045\n",
      "epoch: 98, loss: 0.009875659754572184\n",
      "epoch: 99, loss: 0.009423405583290832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be33a0631cf9438b9fffda070e1a9468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.050577647736053846\n",
      "epoch: 1, loss: 0.045103400629899995\n",
      "epoch: 2, loss: 0.04226283065804327\n",
      "epoch: 3, loss: 0.04115934603234886\n",
      "epoch: 4, loss: 0.04149856638407862\n",
      "epoch: 5, loss: 0.041062474563759534\n",
      "epoch: 6, loss: 0.04024989082995038\n",
      "epoch: 7, loss: 0.03844866603503502\n",
      "epoch: 8, loss: 0.036954835605458\n",
      "epoch: 9, loss: 0.034784147498139906\n",
      "epoch: 10, loss: 0.03198980121954754\n",
      "epoch: 11, loss: 0.030546216034454336\n",
      "epoch: 12, loss: 0.029592668710956126\n",
      "epoch: 13, loss: 0.029422963889400137\n",
      "epoch: 14, loss: 0.027996590533219883\n",
      "epoch: 15, loss: 0.027180071244952773\n",
      "epoch: 16, loss: 0.026398697988040953\n",
      "epoch: 17, loss: 0.026825154621508984\n",
      "epoch: 18, loss: 0.02685912468075981\n",
      "epoch: 19, loss: 0.02615928202917678\n",
      "epoch: 20, loss: 0.02522571792036104\n",
      "epoch: 21, loss: 0.02515701799121795\n",
      "epoch: 22, loss: 0.024481130799183137\n",
      "epoch: 23, loss: 0.0233840326555907\n",
      "epoch: 24, loss: 0.022781966346442747\n",
      "epoch: 25, loss: 0.02183406277830438\n",
      "epoch: 26, loss: 0.021497829626002725\n",
      "epoch: 27, loss: 0.019694794267897137\n",
      "epoch: 28, loss: 0.01865414888171055\n",
      "epoch: 29, loss: 0.01833549377331546\n",
      "epoch: 30, loss: 0.01779603185339558\n",
      "epoch: 31, loss: 0.01743120329181568\n",
      "epoch: 32, loss: 0.018050204566166652\n",
      "epoch: 33, loss: 0.01820455868626274\n",
      "epoch: 34, loss: 0.01719629406978504\n",
      "epoch: 35, loss: 0.017336354131896096\n",
      "epoch: 36, loss: 0.016644878641098003\n",
      "epoch: 37, loss: 0.016078582050557576\n",
      "epoch: 38, loss: 0.01671439731021612\n",
      "epoch: 39, loss: 0.01561656695635049\n",
      "epoch: 40, loss: 0.015411678291152961\n",
      "epoch: 41, loss: 0.015642882079519683\n",
      "epoch: 42, loss: 0.015709847539233622\n",
      "epoch: 43, loss: 0.01583217499390317\n",
      "epoch: 44, loss: 0.016379388653802885\n",
      "epoch: 45, loss: 0.016292545155091348\n",
      "epoch: 46, loss: 0.015603039113830333\n",
      "epoch: 47, loss: 0.01582302107199282\n",
      "epoch: 48, loss: 0.016014467156494867\n",
      "epoch: 49, loss: 0.01586468320523863\n",
      "epoch: 50, loss: 0.015419231391075998\n",
      "epoch: 51, loss: 0.015221637691382359\n",
      "epoch: 52, loss: 0.01523700463922547\n",
      "epoch: 53, loss: 0.015048291859916576\n",
      "epoch: 54, loss: 0.01537819595034569\n",
      "epoch: 55, loss: 0.015146564128174268\n",
      "epoch: 56, loss: 0.015201997897715914\n",
      "epoch: 57, loss: 0.014695917731841632\n",
      "epoch: 58, loss: 0.01498534064002783\n",
      "epoch: 59, loss: 0.014970705501013776\n",
      "epoch: 60, loss: 0.01476431869919232\n",
      "epoch: 61, loss: 0.01524978335556181\n",
      "epoch: 62, loss: 0.014690947362585884\n",
      "epoch: 63, loss: 0.014524497318668853\n",
      "epoch: 64, loss: 0.014753428103521015\n",
      "epoch: 65, loss: 0.015189736916697278\n",
      "epoch: 66, loss: 0.014130032973023208\n",
      "epoch: 67, loss: 0.014649649856845103\n",
      "epoch: 68, loss: 0.01453567116152739\n",
      "epoch: 69, loss: 0.014335041825549224\n",
      "epoch: 70, loss: 0.014633578519040551\n",
      "epoch: 71, loss: 0.014418475027722349\n",
      "epoch: 72, loss: 0.014338540554921788\n",
      "epoch: 73, loss: 0.01464614003769928\n",
      "epoch: 74, loss: 0.014380810314884142\n",
      "epoch: 75, loss: 0.014309909146900078\n",
      "epoch: 76, loss: 0.01403784942866185\n",
      "epoch: 77, loss: 0.014367518739805164\n",
      "epoch: 78, loss: 0.014417816077136133\n",
      "epoch: 79, loss: 0.013884221717627128\n",
      "epoch: 80, loss: 0.014434521154775781\n",
      "epoch: 81, loss: 0.014608278185019473\n",
      "epoch: 82, loss: 0.01416796207820944\n",
      "epoch: 83, loss: 0.014595239477688515\n",
      "epoch: 84, loss: 0.014433793894709309\n",
      "epoch: 85, loss: 0.014441513888618123\n",
      "epoch: 86, loss: 0.014119654638598296\n",
      "epoch: 87, loss: 0.014104068833460024\n",
      "epoch: 88, loss: 0.014222661987665164\n",
      "epoch: 89, loss: 0.014549079644738179\n",
      "epoch: 90, loss: 0.014287877689563622\n",
      "epoch: 91, loss: 0.014338674702832822\n",
      "epoch: 92, loss: 0.014058141309816263\n",
      "epoch: 93, loss: 0.014030665654903398\n",
      "epoch: 94, loss: 0.01405225715812676\n",
      "epoch: 95, loss: 0.014376224018096859\n",
      "epoch: 96, loss: 0.014403250191751102\n",
      "epoch: 97, loss: 0.014398063955663754\n",
      "epoch: 98, loss: 0.014453856846297996\n",
      "epoch: 99, loss: 0.014344653262764968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bc3295268444dd84586a27552d00bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.15261603977051766\n",
      "epoch: 1, loss: 0.10881406213794018\n",
      "epoch: 2, loss: 0.0765448230536076\n",
      "epoch: 3, loss: 0.05996047451238563\n",
      "epoch: 4, loss: 0.05442296295506366\n",
      "epoch: 5, loss: 0.05643606071446896\n",
      "epoch: 6, loss: 0.055693581726594193\n",
      "epoch: 7, loss: 0.05441154885237258\n",
      "epoch: 8, loss: 0.052972893759022865\n",
      "epoch: 9, loss: 0.05223399137805698\n",
      "epoch: 10, loss: 0.05124088986521035\n",
      "epoch: 11, loss: 0.051058409668989536\n",
      "epoch: 12, loss: 0.05043551358611662\n",
      "epoch: 13, loss: 0.04999615120754913\n",
      "epoch: 14, loss: 0.048552287873629904\n",
      "epoch: 15, loss: 0.04873020002809548\n",
      "epoch: 16, loss: 0.048260481067752575\n",
      "epoch: 17, loss: 0.04729883792463121\n",
      "epoch: 18, loss: 0.046405644142147304\n",
      "epoch: 19, loss: 0.044282471886576164\n",
      "epoch: 20, loss: 0.04174432948107639\n",
      "epoch: 21, loss: 0.03917259802410545\n",
      "epoch: 22, loss: 0.03652099421039204\n",
      "epoch: 23, loss: 0.03443796059373379\n",
      "epoch: 24, loss: 0.0317857546151309\n",
      "epoch: 25, loss: 0.030203866038913948\n",
      "epoch: 26, loss: 0.029925478365237984\n",
      "epoch: 27, loss: 0.02916488842537691\n",
      "epoch: 28, loss: 0.027327204207192937\n",
      "epoch: 29, loss: 0.025052200643562016\n",
      "epoch: 30, loss: 0.022846531371932342\n",
      "epoch: 31, loss: 0.02139791944531189\n",
      "epoch: 32, loss: 0.020475428975651706\n",
      "epoch: 33, loss: 0.01946746404397595\n",
      "epoch: 34, loss: 0.01801455614972188\n",
      "epoch: 35, loss: 0.017616492098051585\n",
      "epoch: 36, loss: 0.01696148791825748\n",
      "epoch: 37, loss: 0.015652086012473098\n",
      "epoch: 38, loss: 0.015343110648388322\n",
      "epoch: 39, loss: 0.014465426449347542\n",
      "epoch: 40, loss: 0.014286335585127298\n",
      "epoch: 41, loss: 0.013698054008830604\n",
      "epoch: 42, loss: 0.013089431991439969\n",
      "epoch: 43, loss: 0.012930882657281918\n",
      "epoch: 44, loss: 0.012615795806806418\n",
      "epoch: 45, loss: 0.01300957969995052\n",
      "epoch: 46, loss: 0.01288594943381631\n",
      "epoch: 47, loss: 0.013020550439102633\n",
      "epoch: 48, loss: 0.013227515505727316\n",
      "epoch: 49, loss: 0.01270057601872858\n",
      "epoch: 50, loss: 0.012379148365690122\n",
      "epoch: 51, loss: 0.012961549047674999\n",
      "epoch: 52, loss: 0.012848199482306113\n",
      "epoch: 53, loss: 0.011878319287940817\n",
      "epoch: 54, loss: 0.011915065206207434\n",
      "epoch: 55, loss: 0.012026158639691652\n",
      "epoch: 56, loss: 0.011969616421283786\n",
      "epoch: 57, loss: 0.011563197671731385\n",
      "epoch: 58, loss: 0.011771309941479333\n",
      "epoch: 59, loss: 0.012178225328677666\n",
      "epoch: 60, loss: 0.012069200294481539\n",
      "epoch: 61, loss: 0.011773735963554306\n",
      "epoch: 62, loss: 0.011836187643984386\n",
      "epoch: 63, loss: 0.011763865995516298\n",
      "epoch: 64, loss: 0.011763754151229745\n",
      "epoch: 65, loss: 0.011791090129370312\n",
      "epoch: 66, loss: 0.011334965649175046\n",
      "epoch: 67, loss: 0.011558517051894425\n",
      "epoch: 68, loss: 0.01163811890567398\n",
      "epoch: 69, loss: 0.011238265248490602\n",
      "epoch: 70, loss: 0.01145153030981719\n",
      "epoch: 71, loss: 0.011790561368779418\n",
      "epoch: 72, loss: 0.011585304981693958\n",
      "epoch: 73, loss: 0.011451566939465675\n",
      "epoch: 74, loss: 0.011371982531222354\n",
      "epoch: 75, loss: 0.011694452392107335\n",
      "epoch: 76, loss: 0.011663908565804263\n",
      "epoch: 77, loss: 0.011700346901161156\n",
      "epoch: 78, loss: 0.011461122105972077\n",
      "epoch: 79, loss: 0.011719655471350857\n",
      "epoch: 80, loss: 0.011220631959598569\n",
      "epoch: 81, loss: 0.01175306240336224\n",
      "epoch: 82, loss: 0.011548557632225176\n",
      "epoch: 83, loss: 0.011796118286565254\n",
      "epoch: 84, loss: 0.011850840600953936\n",
      "epoch: 85, loss: 0.0113941052037727\n",
      "epoch: 86, loss: 0.011832998210312555\n",
      "epoch: 87, loss: 0.011337116350545476\n",
      "epoch: 88, loss: 0.011227346130251366\n",
      "epoch: 89, loss: 0.01129952267643203\n",
      "epoch: 90, loss: 0.011174256211839532\n",
      "epoch: 91, loss: 0.011350882404510874\n",
      "epoch: 92, loss: 0.011684749643494306\n",
      "epoch: 93, loss: 0.011199364319177396\n",
      "epoch: 94, loss: 0.011484130020570917\n",
      "epoch: 95, loss: 0.011541581229383098\n",
      "epoch: 96, loss: 0.011806024992913545\n",
      "epoch: 97, loss: 0.011816262396695497\n",
      "epoch: 98, loss: 0.011292814016934211\n",
      "epoch: 99, loss: 0.011467948023086188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ed342ab798461a8e53cb024cb022c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.048242435758708374\n",
      "epoch: 1, loss: 0.03847100417484283\n",
      "epoch: 2, loss: 0.03185989780112217\n",
      "epoch: 3, loss: 0.028734808551530638\n",
      "epoch: 4, loss: 0.025444855289336935\n",
      "epoch: 5, loss: 0.02438683304893556\n",
      "epoch: 6, loss: 0.02365835765845169\n",
      "epoch: 7, loss: 0.022052393391116497\n",
      "epoch: 8, loss: 0.020771594640230737\n",
      "epoch: 9, loss: 0.018776608206189843\n",
      "epoch: 10, loss: 0.01799364281681346\n",
      "epoch: 11, loss: 0.018403970335778976\n",
      "epoch: 12, loss: 0.018301759106477876\n",
      "epoch: 13, loss: 0.018464507635453046\n",
      "epoch: 14, loss: 0.018621267766988428\n",
      "epoch: 15, loss: 0.017788676376208276\n",
      "epoch: 16, loss: 0.01734743164061343\n",
      "epoch: 17, loss: 0.016183473872609072\n",
      "epoch: 18, loss: 0.01541506342589279\n",
      "epoch: 19, loss: 0.014962181034422923\n",
      "epoch: 20, loss: 0.01527248193422288\n",
      "epoch: 21, loss: 0.015186127454681479\n",
      "epoch: 22, loss: 0.015577166819412973\n",
      "epoch: 23, loss: 0.015280862588545212\n",
      "epoch: 24, loss: 0.015154704641036661\n",
      "epoch: 25, loss: 0.014540604982897087\n",
      "epoch: 26, loss: 0.014041098005606014\n",
      "epoch: 27, loss: 0.014026761496327467\n",
      "epoch: 28, loss: 0.014169333657852879\n",
      "epoch: 29, loss: 0.014126728596913513\n",
      "epoch: 30, loss: 0.013804346119309118\n",
      "epoch: 31, loss: 0.01375134829334974\n",
      "epoch: 32, loss: 0.013925580889655792\n",
      "epoch: 33, loss: 0.013750631874115193\n",
      "epoch: 34, loss: 0.013929166227484954\n",
      "epoch: 35, loss: 0.01368813235487801\n",
      "epoch: 36, loss: 0.013741668131009499\n",
      "epoch: 37, loss: 0.013726436866415344\n",
      "epoch: 38, loss: 0.013757805006273684\n",
      "epoch: 39, loss: 0.01356579775767765\n",
      "epoch: 40, loss: 0.013614612251727077\n",
      "epoch: 41, loss: 0.013929995625775973\n",
      "epoch: 42, loss: 0.013519592547712787\n",
      "epoch: 43, loss: 0.01373259422465544\n",
      "epoch: 44, loss: 0.013535510192373743\n",
      "epoch: 45, loss: 0.013289626069404401\n",
      "epoch: 46, loss: 0.013513832305418945\n",
      "epoch: 47, loss: 0.013570968134802021\n",
      "epoch: 48, loss: 0.013635772968621167\n",
      "epoch: 49, loss: 0.013343141062927976\n",
      "epoch: 50, loss: 0.0135169744024605\n",
      "epoch: 51, loss: 0.013117321618668304\n",
      "epoch: 52, loss: 0.013420136932601133\n",
      "epoch: 53, loss: 0.013310430832743076\n",
      "epoch: 54, loss: 0.013097300449702469\n",
      "epoch: 55, loss: 0.012882816629993988\n",
      "epoch: 56, loss: 0.013018102709696807\n",
      "epoch: 57, loss: 0.012893636571686837\n",
      "epoch: 58, loss: 0.012775062228611585\n",
      "epoch: 59, loss: 0.012381509511680138\n",
      "epoch: 60, loss: 0.012027299904317652\n",
      "epoch: 61, loss: 0.010973428107247973\n",
      "epoch: 62, loss: 0.010291954980972686\n",
      "epoch: 63, loss: 0.010067041331356616\n",
      "epoch: 64, loss: 0.009250118556899431\n",
      "epoch: 65, loss: 0.009273324046408408\n",
      "epoch: 66, loss: 0.009305413627124772\n",
      "epoch: 67, loss: 0.009064943040024627\n",
      "epoch: 68, loss: 0.008976308682526022\n",
      "epoch: 69, loss: 0.008401167863333453\n",
      "epoch: 70, loss: 0.008203806831068293\n",
      "epoch: 71, loss: 0.008126488985616902\n",
      "epoch: 72, loss: 0.008706322287317748\n",
      "epoch: 73, loss: 0.008245125501792253\n",
      "epoch: 74, loss: 0.008127808664820982\n",
      "epoch: 75, loss: 0.008171222515425404\n",
      "epoch: 76, loss: 0.007939180548745928\n",
      "epoch: 77, loss: 0.008236073700691208\n",
      "epoch: 78, loss: 0.008008593855144488\n",
      "epoch: 79, loss: 0.007973937431682582\n",
      "epoch: 80, loss: 0.008063906262323702\n",
      "epoch: 81, loss: 0.007854552437889956\n",
      "epoch: 82, loss: 0.007790768624295003\n",
      "epoch: 83, loss: 0.007753866546528959\n",
      "epoch: 84, loss: 0.007972506661199972\n",
      "epoch: 85, loss: 0.007841654500597185\n",
      "epoch: 86, loss: 0.007829075013479845\n",
      "epoch: 87, loss: 0.007391959011487556\n",
      "epoch: 88, loss: 0.00764309663242633\n",
      "epoch: 89, loss: 0.007631124598888709\n",
      "epoch: 90, loss: 0.007588157292881565\n",
      "epoch: 91, loss: 0.007824376378462174\n",
      "epoch: 92, loss: 0.007628994358695691\n",
      "epoch: 93, loss: 0.0073430766332532125\n",
      "epoch: 94, loss: 0.007360872216266146\n",
      "epoch: 95, loss: 0.007272945331557506\n",
      "epoch: 96, loss: 0.007539848431556097\n",
      "epoch: 97, loss: 0.007412508010549348\n",
      "epoch: 98, loss: 0.007196321083107981\n",
      "epoch: 99, loss: 0.007503333607489507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5782f0c082494396cf791f14d3bc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.05055699693001659\n",
      "epoch: 1, loss: 0.04758481535937042\n",
      "epoch: 2, loss: 0.04287936730673578\n",
      "epoch: 3, loss: 0.040374627819743346\n",
      "epoch: 4, loss: 0.03679394192914817\n",
      "epoch: 5, loss: 0.03165945509326674\n",
      "epoch: 6, loss: 0.025142715523569753\n",
      "epoch: 7, loss: 0.018822517507399782\n",
      "epoch: 8, loss: 0.015758867210029594\n",
      "epoch: 9, loss: 0.015287810119838518\n",
      "epoch: 10, loss: 0.014180091899034703\n",
      "epoch: 11, loss: 0.013096221180183094\n",
      "epoch: 12, loss: 0.012642193405923935\n",
      "epoch: 13, loss: 0.01220594235697074\n",
      "epoch: 14, loss: 0.012157560697868575\n",
      "epoch: 15, loss: 0.012232414626119792\n",
      "epoch: 16, loss: 0.01139606869661949\n",
      "epoch: 17, loss: 0.010982062348613651\n",
      "epoch: 18, loss: 0.010995058394233068\n",
      "epoch: 19, loss: 0.011007404680594843\n",
      "epoch: 20, loss: 0.011487461934941202\n",
      "epoch: 21, loss: 0.011628978362448745\n",
      "epoch: 22, loss: 0.012034863165932646\n",
      "epoch: 23, loss: 0.012110188901480044\n",
      "epoch: 24, loss: 0.011733786131716115\n",
      "epoch: 25, loss: 0.011498368346993713\n",
      "epoch: 26, loss: 0.011159945127866453\n",
      "epoch: 27, loss: 0.011289555396415183\n",
      "epoch: 28, loss: 0.011241310867932605\n",
      "epoch: 29, loss: 0.011041106174147261\n",
      "epoch: 30, loss: 0.011139095942398744\n",
      "epoch: 31, loss: 0.011044980318360618\n",
      "epoch: 32, loss: 0.010847946391171235\n",
      "epoch: 33, loss: 0.010847432564677753\n",
      "epoch: 34, loss: 0.010627289329816112\n",
      "epoch: 35, loss: 0.01065866475752236\n",
      "epoch: 36, loss: 0.010642948651817197\n",
      "epoch: 37, loss: 0.010178925852835873\n",
      "epoch: 38, loss: 0.01011861592397435\n",
      "epoch: 39, loss: 0.010548399993949681\n",
      "epoch: 40, loss: 0.010436129990357819\n",
      "epoch: 41, loss: 0.010402661631705978\n",
      "epoch: 42, loss: 0.010348771940818853\n",
      "epoch: 43, loss: 0.01025213822643514\n",
      "epoch: 44, loss: 0.010355570443972659\n",
      "epoch: 45, loss: 0.010409445483742653\n",
      "epoch: 46, loss: 0.01047816748939288\n",
      "epoch: 47, loss: 0.010175145894694794\n",
      "epoch: 48, loss: 0.01011334821280902\n",
      "epoch: 49, loss: 0.009906111445315939\n",
      "epoch: 50, loss: 0.00994858461229198\n",
      "epoch: 51, loss: 0.009907855724352934\n",
      "epoch: 52, loss: 0.010070398717114033\n",
      "epoch: 53, loss: 0.009714141349005069\n",
      "epoch: 54, loss: 0.009938877411682043\n",
      "epoch: 55, loss: 0.009423370460149986\n",
      "epoch: 56, loss: 0.00985327219914572\n",
      "epoch: 57, loss: 0.009803194695158095\n",
      "epoch: 58, loss: 0.00987007113050226\n",
      "epoch: 59, loss: 0.009642275320024244\n",
      "epoch: 60, loss: 0.009828056575167481\n",
      "epoch: 61, loss: 0.00946800856013573\n",
      "epoch: 62, loss: 0.009534211133395365\n",
      "epoch: 63, loss: 0.009938051103244812\n",
      "epoch: 64, loss: 0.009671665498756457\n",
      "epoch: 65, loss: 0.009959840410920717\n",
      "epoch: 66, loss: 0.009709227957525005\n",
      "epoch: 67, loss: 0.009778625261017243\n",
      "epoch: 68, loss: 0.009923800301022712\n",
      "epoch: 69, loss: 0.009982009278275486\n",
      "epoch: 70, loss: 0.009447660605097434\n",
      "epoch: 71, loss: 0.00998449856995492\n",
      "epoch: 72, loss: 0.009745135801379133\n",
      "epoch: 73, loss: 0.00939601747797319\n",
      "epoch: 74, loss: 0.009775842808821367\n",
      "epoch: 75, loss: 0.009678242662760314\n",
      "epoch: 76, loss: 0.0096082779329972\n",
      "epoch: 77, loss: 0.009652326432554103\n",
      "epoch: 78, loss: 0.009671990259023606\n",
      "epoch: 79, loss: 0.009655003364020663\n",
      "epoch: 80, loss: 0.009549521214476324\n",
      "epoch: 81, loss: 0.009622531148645573\n",
      "epoch: 82, loss: 0.009755941676561911\n",
      "epoch: 83, loss: 0.009628982204805457\n",
      "epoch: 84, loss: 0.009778797503099717\n",
      "epoch: 85, loss: 0.009865250213602423\n",
      "epoch: 86, loss: 0.009757399889513\n",
      "epoch: 87, loss: 0.009833904109971075\n",
      "epoch: 88, loss: 0.009735143949617647\n",
      "epoch: 89, loss: 0.009588059621667273\n",
      "epoch: 90, loss: 0.009690950361558585\n",
      "epoch: 91, loss: 0.009619644816412653\n",
      "epoch: 92, loss: 0.00950233968842218\n",
      "epoch: 93, loss: 0.009526873864387218\n",
      "epoch: 94, loss: 0.009366921924243448\n",
      "epoch: 95, loss: 0.01005117247751312\n",
      "epoch: 96, loss: 0.009560648401614998\n",
      "epoch: 97, loss: 0.009664424594044402\n",
      "epoch: 98, loss: 0.009775067648357871\n",
      "epoch: 99, loss: 0.010269169810792773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff31983602f4820ba5fde576a445ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07913462535899683\n",
      "epoch: 1, loss: 0.06970038367984653\n",
      "epoch: 2, loss: 0.06203565091064262\n",
      "epoch: 3, loss: 0.05561463764404713\n",
      "epoch: 4, loss: 0.0514227357260185\n",
      "epoch: 5, loss: 0.04865965783406236\n",
      "epoch: 6, loss: 0.04549191596958025\n",
      "epoch: 7, loss: 0.04383962758105271\n",
      "epoch: 8, loss: 0.04184548570729928\n",
      "epoch: 9, loss: 0.040409624512425184\n",
      "epoch: 10, loss: 0.03891860171440307\n",
      "epoch: 11, loss: 0.03703254917222251\n",
      "epoch: 12, loss: 0.03510885177910242\n",
      "epoch: 13, loss: 0.033635872936436065\n",
      "epoch: 14, loss: 0.03399571665000292\n",
      "epoch: 15, loss: 0.03283934848723048\n",
      "epoch: 16, loss: 0.03208334457218444\n",
      "epoch: 17, loss: 0.03199246714351365\n",
      "epoch: 18, loss: 0.031159360475831344\n",
      "epoch: 19, loss: 0.03104941438977519\n",
      "epoch: 20, loss: 0.02948819838473084\n",
      "epoch: 21, loss: 0.0281714583354771\n",
      "epoch: 22, loss: 0.027498999397787997\n",
      "epoch: 23, loss: 0.026845571955670923\n",
      "epoch: 24, loss: 0.026062789297795312\n",
      "epoch: 25, loss: 0.025452229204109823\n",
      "epoch: 26, loss: 0.0237280695815588\n",
      "epoch: 27, loss: 0.022419040994700986\n",
      "epoch: 28, loss: 0.02106681012831965\n",
      "epoch: 29, loss: 0.019120263979098776\n",
      "epoch: 30, loss: 0.019045536926991607\n",
      "epoch: 31, loss: 0.019087291481832382\n",
      "epoch: 32, loss: 0.018568517061034365\n",
      "epoch: 33, loss: 0.01671354883280246\n",
      "epoch: 34, loss: 0.015275649010023557\n",
      "epoch: 35, loss: 0.015946471099565256\n",
      "epoch: 36, loss: 0.016906771771437852\n",
      "epoch: 37, loss: 0.01664733791355974\n",
      "epoch: 38, loss: 0.01616837310982934\n",
      "epoch: 39, loss: 0.015750684425236527\n",
      "epoch: 40, loss: 0.015929054808645312\n",
      "epoch: 41, loss: 0.015367727926875891\n",
      "epoch: 42, loss: 0.01537305208184224\n",
      "epoch: 43, loss: 0.015470085331853536\n",
      "epoch: 44, loss: 0.014720991430895138\n",
      "epoch: 45, loss: 0.015093296289887622\n",
      "epoch: 46, loss: 0.015002509605632488\n",
      "epoch: 47, loss: 0.01444099434024395\n",
      "epoch: 48, loss: 0.014681065858423081\n",
      "epoch: 49, loss: 0.014482890297843562\n",
      "epoch: 50, loss: 0.013622579821942222\n",
      "epoch: 51, loss: 0.013664653324441535\n",
      "epoch: 52, loss: 0.013685957175220566\n",
      "epoch: 53, loss: 0.013333841631245307\n",
      "epoch: 54, loss: 0.013447437642388206\n",
      "epoch: 55, loss: 0.013340316459314782\n",
      "epoch: 56, loss: 0.013448845818674315\n",
      "epoch: 57, loss: 0.01304432314555804\n",
      "epoch: 58, loss: 0.012842234674773832\n",
      "epoch: 59, loss: 0.013078682881880252\n",
      "epoch: 60, loss: 0.01269198695748032\n",
      "epoch: 61, loss: 0.01305944845370336\n",
      "epoch: 62, loss: 0.013137855701033412\n",
      "epoch: 63, loss: 0.012901203165551472\n",
      "epoch: 64, loss: 0.01324986347289442\n",
      "epoch: 65, loss: 0.013019017123111896\n",
      "epoch: 66, loss: 0.013266521387545891\n",
      "epoch: 67, loss: 0.012730460570156744\n",
      "epoch: 68, loss: 0.012844703767252936\n",
      "epoch: 69, loss: 0.01233020195561343\n",
      "epoch: 70, loss: 0.01282084039448301\n",
      "epoch: 71, loss: 0.012624061224133159\n",
      "epoch: 72, loss: 0.01281370240429076\n",
      "epoch: 73, loss: 0.012029265725249205\n",
      "epoch: 74, loss: 0.012129756295423651\n",
      "epoch: 75, loss: 0.011754355799637737\n",
      "epoch: 76, loss: 0.011804457361351852\n",
      "epoch: 77, loss: 0.011671160664576612\n",
      "epoch: 78, loss: 0.011402306388309753\n",
      "epoch: 79, loss: 0.01125820161858546\n",
      "epoch: 80, loss: 0.010972081140379087\n",
      "epoch: 81, loss: 0.010390497722254241\n",
      "epoch: 82, loss: 0.010617787219362155\n",
      "epoch: 83, loss: 0.00990622646002732\n",
      "epoch: 84, loss: 0.009559079126147405\n",
      "epoch: 85, loss: 0.00893118064965393\n",
      "epoch: 86, loss: 0.008875548641751671\n",
      "epoch: 87, loss: 0.008388092352364627\n",
      "epoch: 88, loss: 0.008007503921601171\n",
      "epoch: 89, loss: 0.007819981128271933\n",
      "epoch: 90, loss: 0.007560628320065046\n",
      "epoch: 91, loss: 0.007722509187086925\n",
      "epoch: 92, loss: 0.0073943981046033416\n",
      "epoch: 93, loss: 0.007259277163162845\n",
      "epoch: 94, loss: 0.007033052366068198\n",
      "epoch: 95, loss: 0.007011813532723864\n",
      "epoch: 96, loss: 0.006970011809312663\n",
      "epoch: 97, loss: 0.006883312048760587\n",
      "epoch: 98, loss: 0.006928586429666829\n",
      "epoch: 99, loss: 0.0067743892804657535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36924bcf779841c486f8c96098295702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.06468202776278396\n",
      "epoch: 1, loss: 0.05066214307679656\n",
      "epoch: 2, loss: 0.04379546007023396\n",
      "epoch: 3, loss: 0.041193300699143724\n",
      "epoch: 4, loss: 0.03920663004581882\n",
      "epoch: 5, loss: 0.036836887973150496\n",
      "epoch: 6, loss: 0.03473549826127558\n",
      "epoch: 7, loss: 0.034463225600644354\n",
      "epoch: 8, loss: 0.033137588642782725\n",
      "epoch: 9, loss: 0.03205789435754377\n",
      "epoch: 10, loss: 0.03023111024916637\n",
      "epoch: 11, loss: 0.027998756563154474\n",
      "epoch: 12, loss: 0.024690526403888007\n",
      "epoch: 13, loss: 0.021789417895646115\n",
      "epoch: 14, loss: 0.020233544704097217\n",
      "epoch: 15, loss: 0.01958592465202487\n",
      "epoch: 16, loss: 0.019293779008954962\n",
      "epoch: 17, loss: 0.01921768192470174\n",
      "epoch: 18, loss: 0.018164395091325607\n",
      "epoch: 19, loss: 0.01730237863052498\n",
      "epoch: 20, loss: 0.016685570522168184\n",
      "epoch: 21, loss: 0.016078240426775647\n",
      "epoch: 22, loss: 0.016017479121549077\n",
      "epoch: 23, loss: 0.015905118432219346\n",
      "epoch: 24, loss: 0.016307988670706236\n",
      "epoch: 25, loss: 0.01624442522209056\n",
      "epoch: 26, loss: 0.01580337449349126\n",
      "epoch: 27, loss: 0.015110207058526426\n",
      "epoch: 28, loss: 0.01418993277826341\n",
      "epoch: 29, loss: 0.014433751793977746\n",
      "epoch: 30, loss: 0.014199759648160337\n",
      "epoch: 31, loss: 0.014182486474847907\n",
      "epoch: 32, loss: 0.014562011258469662\n",
      "epoch: 33, loss: 0.01448234337993215\n",
      "epoch: 34, loss: 0.014117052401799836\n",
      "epoch: 35, loss: 0.01370570186679013\n",
      "epoch: 36, loss: 0.013724069495274294\n",
      "epoch: 37, loss: 0.01313151814534217\n",
      "epoch: 38, loss: 0.013110363566121106\n",
      "epoch: 39, loss: 0.01305367297991898\n",
      "epoch: 40, loss: 0.013304700657445405\n",
      "epoch: 41, loss: 0.013364068427579591\n",
      "epoch: 42, loss: 0.013187923056550466\n",
      "epoch: 43, loss: 0.012967247787802179\n",
      "epoch: 44, loss: 0.012721065593068383\n",
      "epoch: 45, loss: 0.012435862866219094\n",
      "epoch: 46, loss: 0.01211869532550918\n",
      "epoch: 47, loss: 0.01250857706521177\n",
      "epoch: 48, loss: 0.012362982104619662\n",
      "epoch: 49, loss: 0.012255210466990336\n",
      "epoch: 50, loss: 0.011580553811008693\n",
      "epoch: 51, loss: 0.011918029591889513\n",
      "epoch: 52, loss: 0.01183198202457475\n",
      "epoch: 53, loss: 0.011525264946760937\n",
      "epoch: 54, loss: 0.012167573464613732\n",
      "epoch: 55, loss: 0.011825276425972616\n",
      "epoch: 56, loss: 0.012042068549973578\n",
      "epoch: 57, loss: 0.01169906969979098\n",
      "epoch: 58, loss: 0.011759302883161684\n",
      "epoch: 59, loss: 0.011651728338421947\n",
      "epoch: 60, loss: 0.012353732905828932\n",
      "epoch: 61, loss: 0.011596094082572497\n",
      "epoch: 62, loss: 0.011814144661087999\n",
      "epoch: 63, loss: 0.01179316411955732\n",
      "epoch: 64, loss: 0.011914903607900207\n",
      "epoch: 65, loss: 0.0116884366692405\n",
      "epoch: 66, loss: 0.011964085902997367\n",
      "epoch: 67, loss: 0.011898884722462064\n",
      "epoch: 68, loss: 0.011752053973572443\n",
      "epoch: 69, loss: 0.011539689995953586\n",
      "epoch: 70, loss: 0.011504231041829394\n",
      "epoch: 71, loss: 0.011469604330427334\n",
      "epoch: 72, loss: 0.011863321908790464\n",
      "epoch: 73, loss: 0.011353357539968086\n",
      "epoch: 74, loss: 0.011531003149477944\n",
      "epoch: 75, loss: 0.011832384293936547\n",
      "epoch: 76, loss: 0.011746904109644216\n",
      "epoch: 77, loss: 0.011789655823719835\n",
      "epoch: 78, loss: 0.011750545240459995\n",
      "epoch: 79, loss: 0.011451673672714914\n",
      "epoch: 80, loss: 0.01158897543742201\n",
      "epoch: 81, loss: 0.011842533306632761\n",
      "epoch: 82, loss: 0.011527490632297266\n",
      "epoch: 83, loss: 0.011743268907888847\n",
      "epoch: 84, loss: 0.011468851073852218\n",
      "epoch: 85, loss: 0.011928396571845143\n",
      "epoch: 86, loss: 0.011512503631096295\n",
      "epoch: 87, loss: 0.011933748101300599\n",
      "epoch: 88, loss: 0.011764811121891825\n",
      "epoch: 89, loss: 0.011724876619429508\n",
      "epoch: 90, loss: 0.011790859237057989\n",
      "epoch: 91, loss: 0.011730328603398793\n",
      "epoch: 92, loss: 0.011468900286791683\n",
      "epoch: 93, loss: 0.011465868919530857\n",
      "epoch: 94, loss: 0.0116830640997216\n",
      "epoch: 95, loss: 0.011848291771246322\n",
      "epoch: 96, loss: 0.011408598757480579\n",
      "epoch: 97, loss: 0.012007407606547848\n",
      "epoch: 98, loss: 0.011452293068493286\n",
      "epoch: 99, loss: 0.011585151573071818\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e18645bf4f4ae0ad85e76debdcc4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [2, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         reps = 3,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_reps_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 6, 1],\n",
    "                     lr = 0.1)\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=5000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 5\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "\n",
    "y = 0.5*np.ones((n**3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5a53957964d18b6c0eb3919b3a2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f3e4b543e54e02b0d0b35ef0e51c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07637416927999999\n",
      "epoch: 1, loss: 0.04596338136\n",
      "epoch: 2, loss: 0.0269161788\n",
      "epoch: 3, loss: 0.016128381440000002\n",
      "epoch: 4, loss: 0.00959953568\n",
      "epoch: 5, loss: 0.006762073280000001\n",
      "epoch: 6, loss: 0.00674408808\n",
      "epoch: 7, loss: 0.007145074959999999\n",
      "epoch: 8, loss: 0.00786299736\n",
      "epoch: 9, loss: 0.008058812559999998\n",
      "epoch: 10, loss: 0.0076425873600000005\n",
      "epoch: 11, loss: 0.006474841920000001\n",
      "epoch: 12, loss: 0.005154288960000001\n",
      "epoch: 13, loss: 0.003982988879999999\n",
      "epoch: 14, loss: 0.00305114512\n",
      "epoch: 15, loss: 0.002641683920000001\n",
      "epoch: 16, loss: 0.0026878768799999996\n",
      "epoch: 17, loss: 0.00274388944\n",
      "epoch: 18, loss: 0.0027324056\n",
      "epoch: 19, loss: 0.00216237352\n",
      "epoch: 20, loss: 0.0017016034400000005\n",
      "epoch: 21, loss: 0.0011195442399999998\n",
      "epoch: 22, loss: 0.0006073166400000004\n",
      "epoch: 23, loss: 0.00026980592\n",
      "epoch: 24, loss: 0.00015480496\n",
      "epoch: 25, loss: 0.00021477239999999998\n",
      "epoch: 26, loss: 0.00036320968000000007\n",
      "epoch: 27, loss: 0.0004927307999999998\n",
      "epoch: 28, loss: 0.0006153677600000001\n",
      "epoch: 29, loss: 0.00067015592\n",
      "epoch: 30, loss: 0.0006441373600000002\n",
      "epoch: 31, loss: 0.0005681008800000002\n",
      "epoch: 32, loss: 0.00047172031999999993\n",
      "epoch: 33, loss: 0.00039795632000000006\n",
      "epoch: 34, loss: 0.00040435496000000007\n",
      "epoch: 35, loss: 0.00034480639999999994\n",
      "epoch: 36, loss: 0.0003222496800000001\n",
      "epoch: 37, loss: 0.00035795479999999985\n",
      "epoch: 38, loss: 0.00032158943999999987\n",
      "epoch: 39, loss: 0.0002583315200000002\n",
      "epoch: 40, loss: 0.00018265071999999988\n",
      "epoch: 41, loss: 0.00013438960000000005\n",
      "epoch: 42, loss: 6.811263999999995e-05\n",
      "epoch: 43, loss: 3.884824e-05\n",
      "epoch: 44, loss: 2.9078639999999938e-05\n",
      "epoch: 45, loss: 4.7822800000000006e-05\n",
      "epoch: 46, loss: 6.926767999999995e-05\n",
      "epoch: 47, loss: 8.440584000000003e-05\n",
      "epoch: 48, loss: 8.338592e-05\n",
      "epoch: 49, loss: 9.329976000000003e-05\n",
      "epoch: 50, loss: 7.568287999999999e-05\n",
      "epoch: 51, loss: 5.830120000000002e-05\n",
      "epoch: 52, loss: 6.25284e-05\n",
      "epoch: 53, loss: 7.563255999999995e-05\n",
      "epoch: 54, loss: 6.823023999999999e-05\n",
      "epoch: 55, loss: 7.696919999999996e-05\n",
      "epoch: 56, loss: 9.112463999999993e-05\n",
      "epoch: 57, loss: 8.046647999999995e-05\n",
      "epoch: 58, loss: 5.758344000000004e-05\n",
      "epoch: 59, loss: 7.043912e-05\n",
      "epoch: 60, loss: 4.902167999999996e-05\n",
      "epoch: 61, loss: 3.4996879999999996e-05\n",
      "epoch: 62, loss: 4.080935999999998e-05\n",
      "epoch: 63, loss: 4.678471999999998e-05\n",
      "epoch: 64, loss: 4.343943999999999e-05\n",
      "epoch: 65, loss: 3.386415999999997e-05\n",
      "epoch: 66, loss: 2.9517279999999984e-05\n",
      "epoch: 67, loss: 4.556567999999999e-05\n",
      "epoch: 68, loss: 3.6701839999999984e-05\n",
      "epoch: 69, loss: 2.998079999999998e-05\n",
      "epoch: 70, loss: 2.893768000000001e-05\n",
      "epoch: 71, loss: 3.652367999999997e-05\n",
      "epoch: 72, loss: 3.1364239999999956e-05\n",
      "epoch: 73, loss: 3.156904000000001e-05\n",
      "epoch: 74, loss: 3.5675760000000026e-05\n",
      "epoch: 75, loss: 2.803439999999997e-05\n",
      "epoch: 76, loss: 2.8523519999999994e-05\n",
      "epoch: 77, loss: 2.6726239999999988e-05\n",
      "epoch: 78, loss: 2.7620480000000003e-05\n",
      "epoch: 79, loss: 2.9173039999999952e-05\n",
      "epoch: 80, loss: 2.6681519999999963e-05\n",
      "epoch: 81, loss: 2.7710400000000022e-05\n",
      "epoch: 82, loss: 2.7563839999999988e-05\n",
      "epoch: 83, loss: 2.8997280000000017e-05\n",
      "epoch: 84, loss: 3.373375999999998e-05\n",
      "epoch: 85, loss: 2.666016000000002e-05\n",
      "epoch: 86, loss: 2.6102080000000007e-05\n",
      "epoch: 87, loss: 2.622783999999994e-05\n",
      "epoch: 88, loss: 2.6439680000000016e-05\n",
      "epoch: 89, loss: 2.5173919999999984e-05\n",
      "epoch: 90, loss: 2.199079999999998e-05\n",
      "epoch: 91, loss: 2.5018000000000017e-05\n",
      "epoch: 92, loss: 2.2062000000000017e-05\n",
      "epoch: 93, loss: 2.368480000000001e-05\n",
      "epoch: 94, loss: 2.3750319999999986e-05\n",
      "epoch: 95, loss: 3.0166640000000023e-05\n",
      "epoch: 96, loss: 3.0513599999999955e-05\n",
      "epoch: 97, loss: 2.264575999999999e-05\n",
      "epoch: 98, loss: 3.256095999999997e-05\n",
      "epoch: 99, loss: 2.772e-05\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(1)):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_constant_reps_1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 6\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x_qnn = scaler(x, a=0, b=np.pi)\n",
    "x_dnn = (x - np.mean(x, axis=0))/np.std(x, axis=0)\n",
    "\n",
    "y = scaler(y, a=0.1, b=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [3],\n",
    "                         dim = [3, 1],\n",
    "                         reps = 5,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_single_circuit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e87df34b08740868dec66019693fb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbe5326f05e4dfcb7dcdbf587f47b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0875115046055939\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-67c497f1cbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          lr = 0.1)\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mqnn_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, epochs, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, samplewise, include_loss)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             weight_gradient, delta = layer.grad(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 self.a[i], delta, samplewise=samplewise)\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_gradient_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/layers.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, inputs, delta, samplewise)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mweight_partial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mweight_partial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcircuit_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 1,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 2,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(q_bits = [3, 4],\n",
    "                         dim = [3, 4, 1],\n",
    "                         reps = 3,\n",
    "                         backend=backend,\n",
    "                         shots=10000,\n",
    "                         lr = 0.1)\n",
    "    qnn.train(x, y, epochs=100, verbose=True)\n",
    "    qnn_list.append(qnn)\n",
    "\n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_reps_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 6, 1],\n",
    "                     lr = 0.1)\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 8\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6266cfbd05c644769adb6f48aa104930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07515626249013839\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-237807f8a3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                      lr = 0.1)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqnn_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainability_qnn_3D_deep\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, epochs, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, samplewise, include_loss)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_gradient_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/neuralnetwork.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, verbose)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/src/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcircuit_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "qnn = sequential_qnn(q_bits = [3, 4, 4],\n",
    "                     dim = [3, 4, 4, 1],\n",
    "                     reps = 2,\n",
    "                     backend=backend,\n",
    "                     shots=10000,\n",
    "                     lr = 0.1)\n",
    "\n",
    "qnn.train(x, y, epochs=100, verbose=True)\n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D_deep\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 6\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=-2, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "layer1 = QLayer(n_qubits=3, n_features=3, n_targets=3, encoder=Encoder(), ansatz=Ansatz(), sampler=Parity(), reps=2, scale=1, backend=backend, shots=10000)\n",
    "layer2 = Dense(n_features=3, n_targets=1, activation=Identity())\n",
    "layers = [layer1, layer2]\n",
    "network = NeuralNetwork(layers=layers, optimizer = Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_qnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d7edffc04600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_qnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_qnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainability_hybrid_2_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_qnn' is not defined"
     ]
    }
   ],
   "source": [
    "network.train(x, y, epochs=100, verbose=True)\n",
    "saver(network, data_path(\"trainability_hybrid_2_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
